Starting read from Train file...
(9100, 121)
train.shape = (9100, 120)
train_labels.shape = (9100, 1)
(5460, 120) (3640, 120)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.86510989011
[[  0  46  39  63  30  53  30  68   4  58]
 [  0 257   1   0   0   5   3   0   0   3]
 [  0   0 374   1   0   0   0   1   0   0]
 [  0   1   5 212   0   0   0  16   2   5]
 [  0   0   0   0 593   0   0   4   0   1]
 [  0   3   0   0   0 344   3   0   0   0]
 [  0   1   0   0   0   2 239   0   0   0]
 [  0   0   0   3   4   0   0 238   8   0]
 [  0   0   4   2   0   0   0   9 472   6]
 [  0   0   0   4   1   0   0   1   1 420]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.912087912088
[[278   5   1   1  11  20   3   1   8]
 [  1 398  18   0   0   0  17   2   1]
 [  1   8 232   5   0   0  45   2   6]
 [  0   0   1 606   0   0  16   1   1]
 [ 24   1   0   0 391  16   2   0   5]
 [  1   0   0   0   2 239   0   0   0]
 [  0   0   3   4   0   0 238   8   0]
 [  0   4   2   0   0   0   9 472   6]
 [  3   7  28  12   0   0   7   1 466]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.832417582418
[[233   6   4   0  31  13   8   1  13]
 [ 10 384  45   0   2   0  16   4   2]
 [  1   8 134   1   0   0  19   3   8]
 [  1   1  14 597   3   0  21   1  33]
 [ 50   1   1   1 346  14   4   0   8]
 [  9   0   0   0  13 248   0   0   0]
 [  0   1  21  10   0   0 233  17   1]
 [  0   5  30   4   0   0  19 458  31]
 [  4  17  36  15   9   0  17   3 397]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.845054945055
[[238   3   3   0  38  18   7   0  12]
 [ 14 404  62   0   1   0  31   8   5]
 [  1   6 139   0   0   0  24   2   5]
 [  3   1  16 608   3   0  28   1  38]
 [ 42   1   1   0 353  19   4   0  10]
 [  7   0   0   0   4 238   0   0   0]
 [  0   2  14   7   0   0 225  14   1]
 [  0   2   4   0   0   0  10 457   8]
 [  3   4  46  13   5   0   8   5 414]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.656412874298

0.739835164835
[[217  11   9   0  43  29   8   1   7]
 [  7 299  45   0   4   0  18  14  15]
 [  8  47 134   8  11   0  53  19  56]
 [  2   5  10 548   5   0  23   0  24]
 [ 48   5   1   1 307  29   1   2   7]
 [ 17   1   0   0  16 217   0   0   0]
 [  1  12  35  21   4   0 200  13  24]
 [  4  18   7   0   1   0  13 426  15]
 [  4  25  44  50  13   0  21  12 345]]

### RandomForestClassifier ###
score.mean():  0.740291831742

0.797802197802
[[224  13   9   2  40  19   7   2  14]
 [  7 364  62   1   6   0  13   8  18]
 [  6  22 139   6   7   0  32  11  30]
 [  2   1   8 585   2   0  20   1  36]
 [ 47   5   2   3 317  25   6   0   5]
 [ 21   0   0   0  27 231   0   0   0]
 [  1   7  33  12   2   0 237  19  11]
 [  0   6   6   0   0   0  13 440  12]
 [  0   5  26  19   3   0   9   6 367]]

### ExtraTreesClassifier ###
score.mean():  0.737555048857

0.80989010989
[[230   8   7   0  54  18   4   1   9]
 [ 10 372  49   0  11   0  22   9  12]
 [  3  21 154  11   2   0  33  12  39]
 [  2   0   9 592   3   0  18   0  25]
 [ 41   2   1   4 303  20   4   0   7]
 [ 21   0   0   0  23 237   0   0   0]
 [  0   6  29  11   1   0 236  19   5]
 [  1   7   3   0   0   0  10 440  12]
 [  0   7  33  10   7   0  10   6 384]]

###  BaggingClassifier ###
score.mean():  0.851659066839

0.901923076923
[[274   3   0   0  28  12   1   0   8]
 [  0 386   5   0   1   0  16   2   0]
 [  9  22 239   3   1   0  37   5  23]
 [  0   0   6 600   1   0  14   1   8]
 [ 12   0   0   0 364   9   0   0   2]
 [  7   0   0   0   4 254   0   0   0]
 [  0   2  11  17   0   0 261  24   1]
 [  0   3   0   0   1   0   2 455   1]
 [  6   7  24   8   4   0   6   0 450]]
######################################################
(5460, 120) (3640, 120)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.858516483516
[[  0  52  48  71  38  56  35  65   6  45]
 [  0 279   0   1   1   7   4   0   0   0]
 [  0   0 349   1   0   0   0   1   0   0]
 [  0   0   4 203   0   0   0  10   0   6]
 [  0   1   0   0 615   0   0   8   1   4]
 [  0   2   0   0   0 324   3   0   0   0]
 [  0   1   0   0   0   2 232   0   0   0]
 [  0   0   0   3   6   0   0 233   8   0]
 [  0   0   5   1   1   0   0   6 466   1]
 [  0   0   1   7   1   0   0   1   1 424]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.911538461538
[[308   9   4   2  11  21   2   1   5]
 [  0 385  16   0   0   0  15   0   0]
 [  0   5 229   7   0   0  52   2   6]
 [  1   0   0 631   0   0  12   2   4]
 [ 23   0   0   0 375  21   1   1   5]
 [  1   0   0   0   2 232   0   0   0]
 [  0   0   3   6   0   0 233   8   0]
 [  0   5   1   1   0   0   6 466   1]
 [  2   3  34  15   1   0   3   2 459]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.826373626374
[[241   6   7   3  29  29   5   1  11]
 [  9 381  47   0   1   0  17  12   1]
 [  0   3 120   2   0   0  12   1   6]
 [  1   0  14 622   0   0  16   1  23]
 [ 60   2   0   3 334  15   0   1   9]
 [ 19   0   0   0  18 230   0   0   0]
 [  0   0  29  12   0   0 236  21   2]
 [  0   7  15   5   0   0  17 444  28]
 [  5   8  55  15   7   0  21   1 400]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.840659340659
[[240   1   4   1  14  22   1   1   4]
 [ 10 386  58   0   0   0  28   6   0]
 [  0   3 120   1   0   0  14   1  12]
 [  2   0  11 638   0   0  16   3  24]
 [ 66   5   5   0 365  27   8   0  20]
 [ 15   0   0   0   9 225   0   0   0]
 [  0   0  26  12   0   0 234  17   1]
 [  0   7   2   1   0   0   9 452  19]
 [  2   5  61   9   1   0  14   2 400]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.681500770773

0.737637362637
[[239  11  14   1  53  23   2   4   6]
 [  5 303  52   1   6   1  14  18  21]
 [  8  39 119  13   2   0  41  23  45]
 [  2   1   7 573   1   0  14   0  33]
 [ 56  10   2   8 284  20   3   1  10]
 [ 18   0   0   0  30 230   0   0   0]
 [  2  21  46  33   4   0 212  29  23]
 [  2  13   3   4   1   0  12 396  13]
 [  3   9  44  29   8   0  26  11 329]]

### RandomForestClassifier ###
score.mean():  0.72307005466

0.788186813187
[[247  18   7   0  52  23   2   1   7]
 [ 12 350  69   2   7   0  20  18  17]
 [  4  18 131   6   5   0  42  14  38]
 [  2   0   4 614   2   0  12   2  23]
 [ 50   2   2   2 294  15   1   1  15]
 [ 19   0   0   0  25 236   0   0   0]
 [  0   7  38  16   0   0 226  24  13]
 [  0   2   0   0   0   0   6 419  15]
 [  1  10  36  22   4   0  15   3 352]]

### ExtraTreesClassifier ###
score.mean():  0.73681558805

0.801373626374
[[247   9   5   1  46  30   1   3   7]
 [  7 362  66   1   5   0  19  14  17]
 [  2  13 131   9   3   0  36  11  43]
 [  2   0   8 622   1   0  15   2  19]
 [ 50   5   2   0 307  21   1   1   8]
 [ 25   0   0   0  24 223   0   0   0]
 [  2   5  39  10   2   0 238  23   6]
 [  0   5   2   0   0   0   3 423  16]
 [  0   8  34  19   1   0  11   5 364]]

###  BaggingClassifier ###
score.mean():  0.851468906717

0.892582417582
[[301   4   2   1  38  15   0   0   4]
 [  0 361   7   0   0   0  14   1   0]
 [  6  33 242   1   0   0  47   6  20]
 [  1   0   1 628   0   0  10   2   9]
 [ 13   0   0   0 341  13   0   0   1]
 [ 12   0   0   0   6 246   0   0   0]
 [  0   2  12  22   0   0 248  33   1]
 [  0   3   0   0   0   0   3 438   1]
 [  2   4  23  10   4   0   2   2 444]]
######################################################
(5460, 120) (3640, 120)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.870879120879
[[  0  53  32  63  35  53  32  58   2  52]
 [  0 284   1   0   0   3   0   0   0   0]
 [  0   0 350   2   0   1   0   4   0   0]
 [  0   1   2 215   0   0   0   8   1   6]
 [  0   0   0   0 592   1   0   4   0   3]
 [  0   4   0   0   0 333   4   0   0   0]
 [  0   4   0   0   0   2 234   0   0   0]
 [  0   0   0   4   1   0   0 264   5   0]
 [  0   0   5   1   0   0   0   5 468   2]
 [  0   0   0  13   1   0   0   0   2 430]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.915384615385
[[306   3   5   2   8  14   1   1   3]
 [  1 374  19   0   1   0  15   0   1]
 [  1   3 234   6   0   0  36   1  10]
 [  0   0   2 603   1   0  15   0   3]
 [ 30   1   0   0 380  22   3   0   5]
 [  4   0   0   0   2 234   0   0   0]
 [  0   0   4   1   0   0 264   5   0]
 [  0   5   1   0   0   0   5 468   2]
 [  4   4  33  17   1   0   4   3 469]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.834340659341
[[256   3   7   1  25   8   2   1  11]
 [  9 363  47   0   2   0  21  10   2]
 [  1   2 123   2   0   0  13   0  13]
 [  1   2  12 598   2   0  25   0  25]
 [ 65   1   1   1 343  16   2   0   7]
 [ 11   0   0   0  15 246   0   0   0]
 [  0   2  30   8   0   0 244  14   1]
 [  0   6  26   3   0   0  21 451  21]
 [  3  11  52  16   6   0  15   2 413]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.853846153846
[[274   1   4   1  25   9   4   0  11]
 [  8 375  66   0   2   0  23   7   5]
 [  3   4 143   0   0   0  22   0   9]
 [  2   1  12 607   2   0  29   0  31]
 [ 50   1   1   0 355  19   1   0   9]
 [  8   0   0   0   9 242   0   0   0]
 [  0   1  20   4   0   0 238  11   0]
 [  0   5   2   0   0   0  12 455   9]
 [  1   2  50  17   0   0  14   5 419]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.658423200423

0.726098901099
[[221  11   4   8  53  15   3   1   5]
 [ 12 280  48   1  12   0  19  12  20]
 [  4  53 120   6   7   0  42  15  47]
 [  1   2  11 560   2   0  24   4  36]
 [ 65  10   2   0 275  28   2   0   7]
 [ 35   0   0   0  19 227   0   0   0]
 [  0  19  47  17   5   0 197  10  19]
 [  2   3   5   3   1   0  19 423  19]
 [  6  12  61  34  19   0  37  13 340]]

### RandomForestClassifier ###
score.mean():  0.72839692543

0.79478021978
[[249   9   7   3  42  12   3   2   9]
 [  8 334  68   0   1   0  21  14  21]
 [  4  15 137  14   3   0  47  16  38]
 [  1   1   6 597   6   0  21   1  23]
 [ 64   8   0   0 318  20   2   0   8]
 [ 18   0   0   0  19 238   0   0   0]
 [  0   9  32   8   1   0 226  16  11]
 [  0   7   2   0   0   0  10 424  13]
 [  2   7  46   7   3   0  13   5 370]]

### ExtraTreesClassifier ###
score.mean():  0.725081388227

0.803021978022
[[263   9   6   1  54  11   4   2   4]
 [  6 343  70   0   5   0  23  13  18]
 [  2  16 134  10   3   0  48   8  42]
 [  2   0   9 603   5   0  28   1  14]
 [ 52   2   1   0 303  12   1   0   7]
 [ 19   0   0   0  20 247   0   0   0]
 [  1   9  32   5   1   0 214  21  12]
 [  0   5   2   0   0   0  15 430  10]
 [  1   6  44  10   2   0  10   3 386]]

###  BaggingClassifier ###
score.mean():  0.84030167202

0.910989010989
[[312   2   1   0  24   5   1   0   3]
 [  0 361   7   0   3   0  14   1   0]
 [  7  18 249   2   2   0  32   6  25]
 [  0   0   5 602   1   0  10   0   7]
 [ 13   0   0   0 352  11   0   0   1]
 [ 10   0   0   0   5 254   0   0   0]
 [  0   2  11  13   0   0 280  19   0]
 [  0   3   0   0   1   0   3 450   1]
 [  4   4  25  12   5   0   3   2 456]]
######################################################
(5460, 120) (3640, 120)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.864285714286
[[  0  43  37  71  28  64  33  70   4  56]
 [  0 277   1   0   1   7   2   0   0   0]
 [  0   0 374   0   0   0   0   2   0   0]
 [  0   3   7 216   0   0   0   8   1   6]
 [  0   0   0   1 585   0   0   4   1   2]
 [  0   1   0   0   0 324   3   0   0   1]
 [  0   1   0   0   0   1 259   0   0   0]
 [  0   0   0   3   4   0   0 269   4   0]
 [  0   1   4   3   0   0   0   9 442   1]
 [  0   0   0   5   1   0   0   0   0 400]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.917307692308
[[297   4   1   1   9  18   1   0   4]
 [  1 402  14   0   0   0  23   2   0]
 [  3   8 243   6   0   0  45   1   7]
 [  0   0   1 594   0   0  12   2   2]
 [ 22   1   0   0 386  20   0   0   5]
 [  1   0   0   0   1 259   0   0   0]
 [  0   0   3   4   0   0 269   4   0]
 [  1   4   3   0   0   0   9 442   1]
 [  1   4  34  14   0   0   3   1 447]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.835164835165
[[262   3   3   1  32  20   4   0  11]
 [ 10 395  42   0   4   0  18   8   2]
 [  2   7 119   2   1   0  19   1   5]
 [  2   1  11 587   2   0  22   2  27]
 [ 36   1   1   3 337  15   1   0   7]
 [ 13   0   0   0  12 262   0   0   0]
 [  0   1  35   8   0   0 260  14   0]
 [  1   5  37   5   0   0  25 427  23]
 [  0  10  51  13   8   0  13   0 391]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.861538461538
[[274   0   1   1  33  17   1   0  11]
 [ 15 413  62   0   4   0  36   7   3]
 [  2   3 141   2   0   0  14   1   6]
 [  3   1  10 603   2   0  24   2  22]
 [ 24   0   2   0 345  17   2   0   8]
 [  8   0   0   0  10 263   0   0   0]
 [  0   1  24   7   0   0 268  10   0]
 [  0   4   9   2   0   0  12 431  18]
 [  0   1  50   4   2   0   5   1 398]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.658250817626

0.745054945055
[[233   8   5   2  63  25   2   2  13]
 [ 14 321  49   1   5   0  22   8   9]
 [  2  47 128   7   5   0  54  10  49]
 [  1   1   8 551   2   0  21   1  26]
 [ 42   2   7   4 277  25   3   3  12]
 [ 26   0   0   0  32 246   0   0   0]
 [  3  20  42  22   2   0 219  13  19]
 [  1  13  10   0   2   1  17 408   9]
 [  4  11  50  32   8   0  24   7 329]]

### RandomForestClassifier ###
score.mean():  0.729306731905

0.803846153846
[[269  12   7   0  49  25   6   2   9]
 [ 10 360  59   0   7   0  21  13  19]
 [  3  26 141  11   1   0  48  10  21]
 [  2   0   6 590   2   0  29   1  23]
 [ 27   2   0   1 318  28   3   1   6]
 [ 15   0   0   0  14 244   0   0   0]
 [  0  10  40  10   2   0 229  19   9]
 [  0   6   9   0   0   0  10 406  10]
 [  0   7  37   7   3   0  16   0 369]]

### ExtraTreesClassifier ###
score.mean():  0.727480858626

0.813736263736
[[265   5   6   1  42  28   3   2   8]
 [  9 382  59   1   7   0  28  13  25]
 [  1  23 139   5   3   0  42   9  21]
 [  1   0   3 597   3   0  23   0  25]
 [ 28   0   2   0 318  20   2   2   3]
 [ 20   0   0   0  22 249   0   0   0]
 [  0   5  39   9   0   0 241  12   7]
 [  0   6   6   0   0   0  10 410  16]
 [  2   2  45   6   1   0  13   4 361]]

###  BaggingClassifier ###
score.mean():  0.846890662304

0.904120879121
[[296   1   0   1  37  13   0   0   5]
 [  0 388   2   0   4   0  17   1   0]
 [ 11  26 255   3   1   0  45   7  24]
 [  0   1   4 600   1   0   9   2  10]
 [ 14   0   0   0 346  11   0   0   1]
 [  4   0   0   0   3 273   0   0   0]
 [  0   3  12  10   0   0 289  22   2]
 [  0   2   1   0   0   0   1 420   0]
 [  1   2  25   5   4   0   1   0 424]]
######################################################
(5460, 120) (3640, 120)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.856318681319
[[  0  52  41  72  25  63  39  67   3  60]
 [  0 284   1   3   1   3   3   0   0   1]
 [  0   0 359   1   0   1   0   1   0   0]
 [  0   0   4 216   0   0   0   8   1   6]
 [  0   0   0   0 589   0   0   5   0   5]
 [  0   1   0   0   0 321   4   0   0   0]
 [  0   3   0   0   0   4 231   0   0   0]
 [  0   0   0   2   3   0   0 248  10   0]
 [  0   0   6   2   0   0   0  10 468   6]
 [  0   0   1   4   0   1   0   0   0 401]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.910989010989
[[313   5   6   2   9  20   1   0   5]
 [  2 388  17   0   1   0  18   0   0]
 [  0   5 239   6   0   0  39   2   6]
 [  0   0   0 597   0   0  20   0   5]
 [ 21   1   1   0 377  26   1   0   2]
 [  3   0   0   0   4 231   0   0   0]
 [  0   0   2   3   0   0 248  10   0]
 [  0   6   2   0   0   0  10 468   6]
 [  1   7  33  10   2   0   2   2 455]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.82967032967
[[274   5   8   2  27  14   4   0  12]
 [ 10 379  46   0   5   0  20  10   3]
 [  0   3 129   2   0   0  13   1  13]
 [  2   1  11 588   2   0  27   0  36]
 [ 35   0   2   4 334  17   2   0   2]
 [ 16   0   0   0  22 246   0   0   0]
 [  0   2  29   8   0   0 235  17   2]
 [  1  10  23   5   0   0  27 453  29]
 [  2  12  52   9   3   0  11   1 382]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.845604395604
[[277   2   7   1  21  18   2   0  10]
 [ 13 390  63   0   3   0  29   9   4]
 [  1   4 141   0   0   0  22   0   6]
 [  5   1  16 606   2   0  33   0  37]
 [ 31   3   2   0 356  28   2   0   5]
 [ 12   0   0   0  10 231   0   0   0]
 [  0   1  24   6   0   0 231  20   2]
 [  0   7   3   0   0   0  16 452  21]
 [  1   4  44   5   1   0   4   1 394]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.650361736252

0.739285714286
[[229  14   7   0  51  25   2   4   2]
 [ 13 304  50   0   1   0  20  14  18]
 [ 10  45 138  18   1   0  39  14  54]
 [  4   1  10 549   1   0  27   0  27]
 [ 40   3   5   2 302  33   4   0   7]
 [ 34   0   0   0  26 219   0   0   0]
 [  1  18  50  25   6   0 194  19  23]
 [  2   9  10   4   0   0  27 422  14]
 [  7  18  30  20   5   0  26   9 334]]

### RandomForestClassifier ###
score.mean():  0.741758360858

0.8
[[264   9   9   0  41  22   4   1   5]
 [ 12 363  68   0   5   0  17  23  27]
 [  2  18 132   8   4   0  35  12  25]
 [  4   0   4 586   2   0  27   1  28]
 [ 32   3   3   2 311  22   3   0  11]
 [ 26   0   0   0  28 233   0   0   0]
 [  0   9  44   8   0   0 229  17   6]
 [  0   5   3   0   0   0  11 425   8]
 [  0   5  37  14   2   0  13   3 369]]

### ExtraTreesClassifier ###
score.mean():  0.737920951567

0.805494505495
[[270   7   4   0  46  20   3   1   4]
 [ 11 371  62   0   4   0  22  20  23]
 [  3  16 151   5   2   0  34   7  37]
 [  3   0   6 591   3   0  30   0  28]
 [ 29   1   4   1 312  21   1   0   8]
 [ 23   0   0   0  23 236   0   0   0]
 [  0   5  28   9   0   0 220  26   9]
 [  0   5   2   0   0   0  10 424  13]
 [  1   7  43  12   3   0  19   4 357]]

###  BaggingClassifier ###
score.mean():  0.851473374904

0.899175824176
[[304   3   4   1  34  14   1   0   5]
 [  0 377   6   0   3   0  14   1   0]
 [ 10  20 243   1   0   0  38   4  21]
 [  2   0   6 599   1   0  13   0  12]
 [  7   0   0   0 345  13   0   0   0]
 [ 15   0   0   0   6 250   0   0   0]
 [  0   1  10  10   0   0 268  27   1]
 [  0   4   1   0   0   0   3 448   1]
 [  2   7  30   7   4   0   2   2 439]]
######################################################
(5460, 120) (3640, 120)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.860989010989
[[  0  45  38  67  35  67  28  71   5  64]
 [  0 281   1   0   0   6   4   1   0   1]
 [  0   0 351   2   0   1   0   1   0   0]
 [  0   0   4 210   1   0   0  10   1   6]
 [  0   0   0   0 599   0   0   9   1   4]
 [  0   4   0   0   0 334   4   0   0   0]
 [  0   0   0   0   0   2 217   0   0   0]
 [  0   0   0   3   1   0   0 258   3   0]
 [  0   0   4   2   0   0   0   4 462   1]
 [  0   0   0   4   0   1   0   0   0 422]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.916208791209
[[303   2   5   1   9  23   3   0   5]
 [  0 382  16   0   1   0  18   2   0]
 [  1   4 231   6   0   0  47   3  12]
 [  0   0   1 613   0   0  22   1   4]
 [ 26   2   0   1 398  13   2   0   5]
 [  0   0   0   0   2 217   0   0   0]
 [  0   0   3   1   0   0 258   3   0]
 [  0   4   2   0   0   0   4 462   1]
 [  0   4  30  14   1   0   0   1 471]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.838186813187
[[263   1   7   1  33  18   5   0  10]
 [  7 374  42   0   5   0  23  10   3]
 [  0   3 136   2   0   0  17   2   8]
 [  2   1  13 606   2   0  27   1  32]
 [ 42   1   2   3 355  14   2   0   7]
 [ 14   0   0   0  11 221   0   0   0]
 [  0   2  22   9   0   0 245  16   2]
 [  0   5  23   3   0   0  24 443  28]
 [  2  11  43  12   5   0  11   0 408]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.862912087912
[[289   1  11   1  37  20   6   0  16]
 [  4 386  49   0   4   0  30   7   6]
 [  0   3 163   5   1   0  25   3  12]
 [  3   1  13 619   2   0  33   2  33]
 [ 25   1   4   0 356  17   1   0   5]
 [  9   0   0   0   8 216   0   0   0]
 [  0   0  11   5   0   0 247   9   1]
 [  0   4   3   0   0   0  10 449   9]
 [  0   2  34   6   3   0   2   2 416]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.663742433703

0.72967032967
[[232   5   8   2  50  25   4   2   7]
 [ 11 286  37   0  16   0  20   9  23]
 [  4  49 135  12   4   0  57  17  59]
 [  1   0   7 569   6   0  31   1  36]
 [ 50   5   7   1 288  19   3   2  11]
 [ 17   0   0   0  28 209   0   0   0]
 [  1  18  45  12   4   0 189   8  25]
 [  6  12   8   1   1   0  20 422  11]
 [  8  23  41  39  14   0  30  11 326]]

### RandomForestClassifier ###
score.mean():  0.723629701235

0.801373626374
[[256   8   8   1  47  28   3   5   9]
 [  6 342  37   1   5   0  28  19  18]
 [  3  23 161   7   0   0  44   7  54]
 [  1   0   4 607   4   0  25   0  33]
 [ 39   4   4   0 332  21   2   1   4]
 [ 22   0   0   0  19 204   0   0   0]
 [  0   6  33  10   2   0 232  12  10]
 [  0   9   7   0   1   0   8 422   9]
 [  3   6  34  10   1   0  12   6 361]]

### ExtraTreesClassifier ###
score.mean():  0.733146176507

0.807417582418
[[261  11   9   0  43  26   3   3   8]
 [ 11 350  52   0   6   0  29  19  17]
 [  1  18 151   8   0   0  51  12  39]
 [  0   0   7 610   1   0  28   1  25]
 [ 29   1   2   1 332  16   3   1   7]
 [ 25   0   0   0  24 211   0   0   0]
 [  1   5  27   3   2   0 220  16  10]
 [  0   6   3   0   0   0   8 418   6]
 [  2   7  37  14   3   0  12   2 386]]

###  BaggingClassifier ###
score.mean():  0.845608706655

0.901373626374
[[299   2   1   0  34  15   1   0   6]
 [  1 367   3   0   5   0  15   1   0]
 [  7  23 246   3   0   0  39   7  26]
 [  0   0   1 610   1   0  17   1   9]
 [ 11   0   0   0 362   8   0   0   3]
 [ 10   0   0   0   5 230   0   0   0]
 [  0   0  15   9   0   0 281  30   0]
 [  0   3   1   0   0   0   1 432   0]
 [  2   3  21  14   4   0   0   1 454]]
######################################################
(5460, 120) (3640, 120)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.874175824176
[[  0  51  22  64  33  61  22  68   2  43]
 [  0 280   0   1   0   6   3   0   0   1]
 [  0   0 369   2   0   0   0   3   0   0]
 [  0   0   6 216   0   0   0   8   0   3]
 [  0   0   0   0 586   0   0   3   1   3]
 [  0   0   0   0   0 333   4   0   0   0]
 [  0   6   0   0   0   5 241   0   0   0]
 [  0   0   0   2   2   0   0 254   5   0]
 [  0   0   8   3   0   0   0   5 483   4]
 [  0   0   0   6   1   1   0   0   0 420]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.921703296703
[[306   5   5   1   9  11   0   0   5]
 [  1 381  14   0   0   0  21   0   0]
 [  0   6 245   3   0   0  40   1   5]
 [  0   0   0 602   0   0  15   1   3]
 [ 20   1   0   0 391  18   0   0   5]
 [  6   0   0   0   5 241   0   0   0]
 [  0   0   2   2   0   0 254   5   0]
 [  0   8   3   0   0   0   5 483   4]
 [  4   4  25  14   1   0   6   1 452]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.839285714286
[[266   0   7   0  27  17   3   0   7]
 [  8 384  47   0   1   0  24   5   1]
 [  1   1 127   0   0   0   4   0   5]
 [  0   1  11 598   2   0  28   1  30]
 [ 39   1   2   4 340  15   0   0   6]
 [ 19   0   0   0  24 238   0   0   0]
 [  0   0  25   9   0   0 240  20   2]
 [  0  10  22   5   0   0  23 465  26]
 [  4   8  53   6  12   0  19   0 397]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.854395604396
[[292   0   7   1  35  20   3   0   7]
 [  9 393  54   0   0   0  30   6   2]
 [  0   1 125   0   0   0   5   0   4]
 [  3   1  19 608   3   0  39   1  34]
 [ 17   0   2   0 350  17   0   0   8]
 [ 14   0   0   0  15 233   0   0   0]
 [  0   0  28   7   0   0 244  23   2]
 [  0   7   2   0   0   0   8 459  11]
 [  2   3  57   6   3   0  12   2 406]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.678007200177

0.740659340659
[[241  12   9   2  60  19   1   0   5]
 [  5 307  52   0   2   0  27  20  15]
 [  5  34 116   9   2   0  37  17  50]
 [  1   1  11 553   2   0  23   1  37]
 [ 42   5   1   3 290  16   5   2   9]
 [ 30   0   0   0  40 235   0   0   0]
 [  5  13  52  24   2   0 199  22  13]
 [  3  20   4   2   0   0  22 423  13]
 [  5  13  49  29   8   0  27   6 332]]

### RandomForestClassifier ###
score.mean():  0.738849398069

0.810164835165
[[254   8   8   2  41  21   1   1   5]
 [  9 368  59   0   1   0  25  16  17]
 [  3  10 151   5   4   0  35  12  36]
 [  2   0   4 593   4   0  27   1  31]
 [ 42   0   3   2 316  12   2   0   9]
 [ 27   0   0   0  33 237   0   0   0]
 [  0   5  30  14   0   0 235  18   9]
 [  0   9   8   0   1   0   8 439  11]
 [  0   5  31   6   6   0   8   4 356]]

### ExtraTreesClassifier ###
score.mean():  0.730219881405

0.809340659341
[[259   8   7   0  42  22   2   2   7]
 [  6 370  73   0   6   0  33  18  23]
 [  3  12 133   2   3   0  20   6  36]
 [  1   1   8 599   3   0  25   0  26]
 [ 32   1   0   0 316  14   2   0   5]
 [ 34   0   0   0  28 234   0   0   0]
 [  1   3  29   4   2   0 243  23   9]
 [  0   8   6   0   0   0   7 438  14]
 [  1   2  38  17   6   0   9   4 354]]

###  BaggingClassifier ###
score.mean():  0.847446782472

0.907142857143
[[299   2   2   1  36  12   0   0   4]
 [  1 387   4   0   1   0  20   2   1]
 [  9  11 243   1   2   0  31   2  17]
 [  0   0   5 595   0   0  10   2   8]
 [ 12   0   0   0 357   8   0   0   1]
 [ 12   0   0   0   7 250   0   0   0]
 [  0   0  16  13   0   0 273  28   0]
 [  0   3   1   0   0   0   1 456   1]
 [  4   2  23  12   3   0   6   1 442]]
######################################################
(5460, 120) (3640, 120)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.858241758242
[[  0  42  31  83  35  57  30  70   4  48]
 [  0 290   3   0   0   6   4   1   0   1]
 [  0   0 367   2   0   0   0   7   0   0]
 [  0   0   3 197   0   0   0  10   2   6]
 [  0   1   0   0 606   0   0   9   2   2]
 [  0   4   0   0   0 312   2   0   0   0]
 [  0   4   0   0   0   3 247   0   0   0]
 [  0   0   0   2   4   0   0 222   9   0]
 [  0   0   6   1   1   0   0   7 457   4]
 [  0   0   0  10   0   0   0   0   0 426]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.903846153846
[[308   9   1   1  13  19   2   1   5]
 [  0 386  22   0   0   0  27   0   2]
 [  0   4 228   7   0   0  39   3   8]
 [  1   0   0 618   0   0  24   3   2]
 [ 24   0   1   0 362  17   1   0   4]
 [  4   0   0   0   3 247   0   0   0]
 [  0   0   2   4   0   0 222   9   0]
 [  0   6   1   1   0   0   7 457   4]
 [  4   5  40  15   0   0   4   1 462]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.829945054945
[[263   6   3   1  28  23   7   1  11]
 [  4 380  42   0   2   0  27   4   2]
 [  0   0 130   1   1   0  13   2   6]
 [  2   1  14 618   4   0  32   3  27]
 [ 46   2   3   2 323  13   2   0   5]
 [ 20   0   0   0  14 247   0   0   0]
 [  0   0  30  13   0   0 214  22   2]
 [  0   6  25   5   0   0  16 440  28]
 [  6  15  48   6   6   0  15   2 406]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.84532967033
[[261   3   0   0  16  19   3   0   8]
 [  4 391  56   0   2   0  39   8   3]
 [  1   1 134   1   0   0  13   0   8]
 [  3   1  11 627   3   0  34   3  19]
 [ 56   3   5   0 351  27   6   1  11]
 [ 14   0   0   0   5 237   0   0   0]
 [  0   0  28  12   0   0 215  20   0]
 [  0   7   1   0   0   0   5 437  14]
 [  2   4  60   6   1   0  11   5 424]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.641783397311

0.742857142857
[[245  14   6   1  50  28   4   5   9]
 [  3 297  52   1   9   0  22  16  17]
 [  0  47 120   4   2   0  42  13  41]
 [  2   0  10 592   4   0  24   1  25]
 [ 51   6   4   0 271  24   2   2  10]
 [ 28   1   0   0  27 230   0   0   0]
 [  5  20  36  22   5   0 198  15  27]
 [  4  12  11   0   2   1   8 406  13]
 [  3  13  56  26   8   0  26  16 345]]

### RandomForestClassifier ###
score.mean():  0.726558259289

0.80467032967
[[266  13   4   0  41  17   3   4  10]
 [  2 357  60   0   5   0  27  13  22]
 [  2  16 138   8   1   0  43   8  29]
 [  3   1   5 618   4   0  28   0  19]
 [ 48   2   4   0 304  23   3   1   7]
 [ 20   0   0   0  18 243   0   0   0]
 [  0  11  37  12   1   0 208  25   7]
 [  0   1   5   0   1   0   5 414  12]
 [  0   9  42   8   3   0   9   9 381]]

### ExtraTreesClassifier ###
score.mean():  0.732230796606

0.815934065934
[[270  11   2   0  46  16   4   4   7]
 [  4 365  47   0   9   0  28  19  25]
 [  1  16 166   7   3   0  33   5  24]
 [  2   1   8 618   3   0  22   0  24]
 [ 40   2   2   1 290  22   3   1   7]
 [ 23   0   0   0  20 245   0   0   0]
 [  0   7  24   9   0   0 221  27   9]
 [  0   3   3   0   0   0   4 412   8]
 [  1   5  43  11   7   0  11   6 383]]

###  BaggingClassifier ###
score.mean():  0.850001406896

0.893406593407
[[313   4   0   0  32   6   2   0   6]
 [  0 378   6   0   3   0  27   2   1]
 [  1  18 239   2   4   0  36   6  20]
 [  1   0   9 612   2   0  15   2   9]
 [ 14   0   0   0 328  12   0   0   1]
 [  8   0   0   0   6 265   0   0   0]
 [  0   1   9  15   0   0 242  36   0]
 [  0   4   1   0   0   0   1 426   1]
 [  4   5  31  17   3   0   3   2 449]]
######################################################
(5460, 120) (3640, 120)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.862637362637
[[  0  60  33  78  31  60  26  62   3  61]
 [  0 299   1   0   1   3   4   0   0   0]
 [  0   0 373   1   0   0   0   0   0   0]
 [  0   0   3 217   0   0   0   8   0   3]
 [  0   0   0   0 559   0   0   4   1   5]
 [  0   0   0   0   0 325   5   0   0   0]
 [  0   5   0   0   0   1 260   0   0   0]
 [  0   0   0   1   4   0   0 226   4   0]
 [  0   0   8   3   0   0   0   9 473   0]
 [  0   0   1   9   1   0   0   0   1 408]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.908241758242
[[323   5   5   2   6  11   2   0   4]
 [  3 393  21   1   0   0  18   0   3]
 [  0   4 236   7   0   0  35   2   7]
 [  0   0   0 570   0   0  14   1   5]
 [ 32   0   0   0 382  24   1   0  15]
 [  5   0   0   0   1 260   0   0   0]
 [  0   0   1   4   0   0 226   4   0]
 [  0   8   3   0   0   0   9 473   0]
 [  1   9  43  12   0   0   4   2 443]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.817857142857
[[261   5   7   3  29  19   5   0  19]
 [ 14 388  38   1   2   0  16   4   3]
 [  1   2 125   1   0   0  11   1   9]
 [  1   1  12 563   1   0  27   1  32]
 [ 59   2   1   3 330  22   4   0   8]
 [ 26   0   0   0  16 254   0   0   0]
 [  0   1  30  11   0   0 206   8   1]
 [  0  10  47   5   0   0  28 467  22]
 [  2  10  49   9  11   0  12   1 383]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.838461538462
[[273   2   4   2  26  11   5   0  17]
 [ 15 397  57   1   3   0  30   3   4]
 [  0   3 145   0   0   0  16   2   6]
 [  2   1  14 569   1   0  30   1  23]
 [ 57   2   1   0 347  36   3   1  11]
 [ 17   0   0   0   7 248   0   0   0]
 [  0   1  20   9   0   0 207  10   2]
 [  0   7   4   0   0   0  12 462  10]
 [  0   6  64  15   5   0   6   3 404]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.660988740278

0.736813186813
[[254   9   5   2  48  23   1   2   9]
 [  8 317  51   1  12   1  15  14  17]
 [  6  34 118  11   2   0  45  14  34]
 [  1   1  12 529   3   0  19   0  30]
 [ 57   7   3   0 287  37   3   1  14]
 [ 27   0   0   0  19 234   0   0   0]
 [  1  19  46  14   4   0 186  15  17]
 [  1  14   9   0   1   0  17 417  16]
 [  9  18  65  39  13   0  23  19 340]]

### RandomForestClassifier ###
score.mean():  0.736266740187

0.806318681319
[[273  10   7   2  42  16   2   2   5]
 [  5 371  63   1   3   0  23  16  13]
 [  3  17 158   5   3   0  32   5  35]
 [  2   1   5 561   2   0  21   0  28]
 [ 46   0   3   1 313  26   5   1  16]
 [ 33   0   0   0  24 253   0   0   0]
 [  0   3  33  12   1   0 207  15   8]
 [  0   7   2   0   0   0  12 438  11]
 [  2  10  38  14   1   0   7   5 361]]

### ExtraTreesClassifier ###
score.mean():  0.724358351988

0.808791208791
[[287   8   6   1  44  18   4   2   7]
 [  4 362  65   0   7   0  22  17  23]
 [  6  18 152   6   1   0  33   7  27]
 [  2   1   7 569   1   0  26   0  25]
 [ 42   2   2   1 313  19   3   1  13]
 [ 21   0   0   0  20 258   0   0   0]
 [  0   7  29  16   0   0 200  16   8]
 [  0   9   3   0   0   0  11 437   8]
 [  2  12  45   3   3   0  10   2 366]]

###  BaggingClassifier ###
score.mean():  0.855317874723

0.896703296703
[[328   2   3   1  27   9   0   0  10]
 [  0 385   4   0   2   0  16   2   1]
 [  7  19 254   2   0   0  37   6  22]
 [  1   0   2 565   1   0  11   1   9]
 [ 12   0   0   0 349  15   0   0   3]
 [ 15   0   0   0   5 271   0   0   0]
 [  0   2  12  17   0   0 239  30   1]
 [  0   5   1   0   0   0   3 442   0]
 [  1   6  33  11   5   0   3   1 431]]
######################################################
(5460, 120) (3640, 120)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.857142857143
[[  0  50  48  76  35  68  22  75   3  45]
 [  0 286   2   0   1   5   2   0   0   0]
 [  0   1 350   3   0   0   0   4   0   0]
 [  0   0   6 204   0   0   0  13   1   6]
 [  0   0   0   0 598   1   0   4   0   4]
 [  0   1   0   0   0 316   3   0   0   0]
 [  0   2   0   0   0   4 247   0   0   0]
 [  0   0   0   3   2   0   0 224   7   0]
 [  0   0   2   2   1   0   0   3 487   2]
 [  0   0   1   6   3   1   0   1   1 408]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.911263736264
[[312   6   4   1  10  16   3   0  10]
 [  2 386  22   0   0   0  20   0   0]
 [  0   9 230  12   0   0  51   3   6]
 [  0   0   0 611   1   0  17   0   4]
 [ 21   1   0   0 379  11   1   0   2]
 [  2   0   0   0   4 247   0   0   0]
 [  0   0   3   2   0   0 224   7   0]
 [  0   2   2   1   0   0   3 487   2]
 [  3   5  33  13   1   0   5   2 441]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.826373626374
[[260   6   4   2  30  14   6   0  13]
 [ 10 372  56   0   2   0  16   9   1]
 [  1   7 129   0   0   0  16   0   7]
 [  1   1  13 600   1   0  23   0  22]
 [ 46   2   0   4 334  16   2   0   3]
 [ 19   0   0   0  19 244   0   0   0]
 [  0   3  21  10   0   0 216  29   1]
 [  0   5  29   6   0   0  27 460  25]
 [  3  13  42  18   9   0  18   1 393]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.839835164835
[[259   2   4   1  18  16   3   0  10]
 [ 12 388  74   0   3   0  33  11   4]
 [  3   4 134   0   0   0  22   1   6]
 [  2   1  12 610   1   0  29   1  20]
 [ 52   1   3   2 362  25   4   0   8]
 [ 12   0   0   0   9 233   0   0   0]
 [  0   1  16   8   0   0 211  23   1]
 [  0   5   3   0   0   0  11 462  18]
 [  0   7  48  19   2   0  11   1 398]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.679489344529

0.732967032967
[[241  18  11   0  54  17   4   2  12]
 [ 10 308  56   1   6   0  17  14  11]
 [  8  31 118   9   6   0  63  14  48]
 [  1   0   8 567   0   0  22   0  32]
 [ 46   8   3   0 282  29   1   0   8]
 [ 21   0   0   0  29 228   0   0   1]
 [  3  19  43  31   2   0 179  23  20]
 [  2  10   4   0   1   0  13 426  14]
 [  8  15  51  32  15   0  25  20 319]]

### RandomForestClassifier ###
score.mean():  0.732244322563

0.78956043956
[[262  16   6   0  39  15   3   1  10]
 [  9 351  76   0   5   0  22  17  16]
 [  5  14 127  14   4   0  37  10  32]
 [  1   0   7 596   2   0  25   0  31]
 [ 40   2   3   0 312  23   4   2   6]
 [ 22   0   0   0  21 236   0   0   0]
 [  0   5  33  12   1   0 217  29  14]
 [  0  11   4   0   2   0   6 429  12]
 [  1  10  38  18   9   0  10  11 344]]

### ExtraTreesClassifier ###
score.mean():  0.741751529501

0.804120879121
[[265  12   6   1  41  25   5   2   8]
 [  6 356  68   0   3   0  25  15  19]
 [  3  19 136   9   1   0  39   5  35]
 [  2   0   3 605   1   0  18   1  28]
 [ 41   5   1   0 322  16   3   0   5]
 [ 21   0   0   0  20 233   0   0   0]
 [  0   3  24  13   0   0 208  17   3]
 [  2   5   4   0   0   0   7 447  12]
 [  0   9  52  12   7   0  19  12 355]]

###  BaggingClassifier ###
score.mean():  0.860446812563

0.889010989011
[[304   4   1   1  37  12   0   0   8]
 [  1 362   5   0   2   0  19   1   0]
 [ 10  35 246   5   1   0  50   7  20]
 [  1   1   6 611   1   0  14   0  11]
 [ 12   0   0   0 339   6   0   0   1]
 [  8   0   0   0   8 256   0   0   0]
 [  0   2  12  15   0   0 235  30   1]
 [  0   2   1   0   0   0   1 459   0]
 [  4   3  23   8   7   0   5   2 424]]
######################################################
######################################################
comb 0 :
[ 0.86510989  0.85851648  0.87087912  0.86428571  0.85631868  0.86098901
  0.87417582  0.85824176  0.86263736  0.85714286]
0.86282967033
comb 1 :
[ 0.91208791  0.91153846  0.91538462  0.91730769  0.91098901  0.91620879
  0.9217033   0.90384615  0.90824176  0.91126374]
0.912857142857
comb 2 :
[ 0.83241758  0.82637363  0.83434066  0.83516484  0.82967033  0.83818681
  0.83928571  0.82994505  0.81785714  0.82637363]
0.830961538462
comb 3 :
[ 0.84505495  0.84065934  0.85384615  0.86153846  0.8456044   0.86291209
  0.8543956   0.84532967  0.83846154  0.83983516]
0.848763736264
comb 4 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 5 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 6 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 7 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 8 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 9 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 0 :
[ 0.73983516  0.73763736  0.7260989   0.74505495  0.73928571  0.72967033
  0.74065934  0.74285714  0.73681319  0.73296703]
0.737087912088
ens 1 :
[ 0.7978022   0.78818681  0.79478022  0.80384615  0.8         0.80137363
  0.81016484  0.80467033  0.80631868  0.78956044]
0.79967032967
ens 2 :
[ 0.80989011  0.80137363  0.80302198  0.81373626  0.80549451  0.80741758
  0.80934066  0.81593407  0.80879121  0.80412088]
0.807912087912
ens 3 :
[ 0.90192308  0.89258242  0.91098901  0.90412088  0.89917582  0.90137363
  0.90714286  0.89340659  0.8967033   0.88901099]
0.899642857143
ens 4 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 5 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 6 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 7 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 8 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 9 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
