Starting read from Train file...
(9100, 257)
train.shape = (9100, 256)
train_labels.shape = (9100, 1)
(5460, 256) (3640, 256)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.186813186813
[[  0 322 395 217 113 347 269 241 203 389]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0  11   3  14 459  25   3  21  46   8]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   7   4  53  95  11   0  86 221  77]
 [  0   0   0   0   0   0   0   0   0   0]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.407967032967
[[175  14  14   3  46  55   3   4  12]
 [ 17 253  23   2  90  13  42  49  62]
 [  8   1  65  22  21   0  16  12  48]
 [ 83  20  25 505  77 176  81  78  55]
 [ 40  73  33  12 103  27  35  23  57]
 [  0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0]
 [  7   4  53  95  11   0  86 221  77]
 [ 10  37  71  28  35   1  85  83 163]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.466758241758
[[188  26  15   5  46  27   8  11  18]
 [ 34 278  43  12 103   7  51  64  92]
 [  4   1  42   9  20   1  12   4  22]
 [ 24  30  39 519  84  21  71  64  51]
 [  8  10  16   9  22   1  18   2  30]
 [ 53  12   1   0  53 211   3   1   2]
 [  0   0   0   9   0   0   4   3   5]
 [ 15  11  64  85  18   3 116 292 111]
 [ 14  34  64  19  37   1  65  29 143]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.528021978022
[[171  14  11   2  33  29   3   5   9]
 [ 16 259  19   2  64   6  29  52  48]
 [  4   1  61  13  13   0  12   7  35]
 [ 14   5  21 559  31   4  45  47  23]
 [ 66  85  56  13 191  29  65  30  90]
 [ 52   9   1   0  28 203   0   0   0]
 [  1   2   2   9   5   0  37  16  21]
 [  9   7  52  54  12   1  98 282  89]
 [  7  20  61  15   6   0  59  31 159]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.548889461408

0.606593406593
[[172  13   6   0  62  34   4   3  10]
 [ 14 241  34   1  18   1  28  31  44]
 [  2  26 130   2   3   0  27  18  79]
 [  2   1   0 582   0   0  31  43   1]
 [ 77  18   4   0 256  28   7   5  12]
 [ 45   2   0   0  28 208   0   0   1]
 [  5  26  25  35   8   0 121  77  57]
 [  6  30  12  41   2   0  73 263  35]
 [ 17  45  73   6   6   1  57  30 235]]

### RandomForestClassifier ###
score.mean():  0.632408827205

0.687362637363
[[214  15  13   0  48  25   9   4  13]
 [ 23 307  32   3  14   0  33  40  41]
 [  1   9 154   1   1   0  20   3  65]
 [  0   0   0 617   0   0  32  60   4]
 [ 64  10   6   0 286  17   2   3  18]
 [ 35   0   0   0  26 230   0   0   0]
 [  1  18  15  18   5   0 139  62  43]
 [  0  12   5  26   1   0  66 287  22]
 [  2  31  59   2   2   0  47  11 268]]

### ExtraTreesClassifier ###
score.mean():  0.629482245861

0.694230769231
[[215  16  12   0  54  20   6   4  18]
 [ 21 311  29   4  11   0  29  34  42]
 [  2  10 162   0   1   0  30   9  65]
 [  0   0   0 615   0   0  26  49   4]
 [ 61   6   4   0 289  23   1   2   6]
 [ 35   0   0   0  25 229   0   0   0]
 [  3  20   9  17   1   0 140  58  47]
 [  0  18   5  30   0   0  64 301  27]
 [  3  21  63   1   2   0  52  13 265]]

###  BaggingClassifier ###
score.mean():  0.425633514506

0.458516483516
[[166  17  15   5  47  57   3   4  12]
 [ 20 262  26   1  91  14  43  54  64]
 [  6   2  61  17  16   0   9   9  37]
 [ 13   4   9 458  25   3  21  48   9]
 [ 42  67  32  11 104  26  33  22  56]
 [ 75  10   2   0  42 171   1   1   8]
 [  2   3  10  42  16   0  60  29  41]
 [  9   4  58 101  11   0  88 221  81]
 [  7  33  71  32  31   1  90  82 166]]
######################################################
(5460, 256) (3640, 256)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.183516483516
[[  0 301 418 234 130 349 274 240 206 411]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0  16   0   9 445  19  13  20  47  10]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   1   5  41  71   6   0  81 223  70]
 [  0   0   0   0   0   0   0   0   0   0]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.397527472527
[[156  13  16   5  68  64   4   7  19]
 [ 18 245  25   4  91  13  45  47  62]
 [ 12   3  59  24  19   0  15  20  48]
 [ 81  16  22 496  66 187  82  85  59]
 [ 42 100  43  11  99  23  37  22  64]
 [  0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0]
 [  1   5  41  71   6   0  81 223  70]
 [  8  41  78  35  25   0  77  72 169]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.471428571429
[[162  19  17   7  59  31   9  10  21]
 [ 20 291  38  10  87  15  43  53  72]
 [ 10   2  43  11  19   0  10  15  41]
 [ 33  24  43 508  65  23  73  40  47]
 [ 24  18  17   9  52   4  32  16  47]
 [ 45  11   0   1  43 212   1   1   3]
 [  0   0   2   8   0   0   3   2   2]
 [ 11  21  57  73  13   0 113 297 110]
 [ 13  37  67  19  36   2  57  42 148]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.507142857143
[[167  14  10   4  58  39   5   7  16]
 [ 16 248  14   5  55  11  29  42  43]
 [  6   2  58  11  10   0  14  10  40]
 [ 19   1  31 545  21  10  46  41  22]
 [ 58 108  80  21 185  18  90  70 140]
 [ 43   8   0   0  27 209   1   1   3]
 [  0   1   3   8   2   0  31  13  14]
 [  4   9  32  40   9   0  68 256  66]
 [  5  32  56  12   7   0  57  36 147]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.550002628838

0.601923076923
[[167  20   7   0  76  39   6   1  19]
 [ 15 260  23   7  16   1  31  31  45]
 [  3  29 124   0   8   0  14  13  72]
 [  0   1   2 546   1   0  33  33  11]
 [ 68  18   1   0 228  26   5   5  10]
 [ 44   1   0   0  27 219   0   0   1]
 [  5  23  32  36   8   1 112  69  53]
 [  1  22   9  50   7   1  72 286  31]
 [ 15  49  86   7   3   0  68  38 249]]

### RandomForestClassifier ###
score.mean():  0.64211796513

0.689010989011
[[189  20   4   0  63  22   6   2  21]
 [ 18 330  26   3  18   1  32  37  49]
 [  5  19 163   0   3   0  17   7  60]
 [  1   1   0 591   1   0  30  38   3]
 [ 53   9   3   0 259  22   3   4  13]
 [ 45   0   0   0  23 242   0   0   0]
 [  2  10  15  18   3   0 127  54  27]
 [  1   9   3  32   3   0  71 312  23]
 [  4  25  70   2   1   0  55  22 295]]

### ExtraTreesClassifier ###
score.mean():  0.645774035603

0.696153846154
[[200  23   8   0  67  19   4   1  19]
 [ 14 342  25   5  18   0  45  41  44]
 [  3   8 160   1   4   0  25   5  47]
 [  1   0   0 583   1   0  19  33   5]
 [ 58   4   2   0 264  21   5   2   9]
 [ 36   0   0   0  15 247   0   0   0]
 [  3   7   9  17   2   0 116  63  39]
 [  0  12   5  37   2   0  69 310  16]
 [  3  27  75   3   1   0  58  21 312]]

###  BaggingClassifier ###
score.mean():  0.429284431347

0.447252747253
[[163  12  17   6  68  67   4   8  19]
 [ 20 242  25   6  91  12  49  50  69]
 [  9   2  53  22  14   0  15  16  41]
 [ 15   1  10 446  18  14  19  48   9]
 [ 39 104  40  10 102  22  40  19  61]
 [ 59   8   2   0  36 172   0   2   5]
 [  1   7  11  49  12   0  53  34  40]
 [  2   4  39  75   7   0  90 224  74]
 [ 10  43  87  32  26   0  71  75 173]]
######################################################
(5460, 256) (3640, 256)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.173626373626
[[  0 325 405 233 135 372 280 232 216 397]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0  12   0  13 425  20   8  25  62  15]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   3   2  26  92   7   0  79 207  49]
 [  0   0   0   0   0   0   0   0   0   0]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.390384615385
[[178  12  12   7  60  64   1   5  19]
 [ 21 248  28   3 114  21  37  43  70]
 [  6   4  68  19  14   0  14  13  49]
 [ 76  16  34 462  76 183  80  94  56]
 [ 47  79  38  20  95  19  38  16  55]
 [  0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0]
 [  3   2  26  92   7   0  79 207  49]
 [  9  46  66  49  33   1  87 107 163]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.456043956044
[[194  17  25  10  71  38  11  11  28]
 [ 16 265  32  14 106  17  38  49  79]
 [  5   2  50   9  16   0  10   9  38]
 [ 43  26  32 487  74  27  65  56  40]
 [ 23  18  21  13  41   2  30  17  37]
 [ 33  14   0   0  40 201   0   3   2]
 [  0   0   0   6   0   0   9   1   0]
 [ 14  23  50  96  13   2 125 300 124]
 [ 12  42  62  17  38   1  48  39 113]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.501648351648
[[187   8  12   6  49  43   2   6  13]
 [ 15 241  20   3  55  15  26  42  56]
 [  4   1  69  15   7   0  11   8  44]
 [  9   5  19 501  16   7  36  55  21]
 [ 96 107  71  35 229  20 101  67 133]
 [ 22   7   0   0  32 202   0   0   1]
 [  2   2   4  15   1   0  22  12  10]
 [  3   4  17  56   7   1  81 245  53]
 [  2  32  60  21   3   0  57  50 130]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.552742465756

0.607142857143
[[182  21   8   1  79  35   4   4  12]
 [ 21 240  27   3  21   0  25  24  33]
 [  4  31 131   4   3   0  23  17  76]
 [  0   0   1 552   0   0  28  34  10]
 [ 82  13   7   1 256  30   8   4  14]
 [ 38   0   0   0  22 222   0   0   1]
 [  4  28  15  34   6   0 111  78  52]
 [  3  23  13  49   3   0  76 281  28]
 [  6  51  70   8   9   1  61  43 235]]

### RandomForestClassifier ###
score.mean():  0.632971765329

0.690934065934
[[218  15   3   0  66  33   5   2  13]
 [ 18 324  33   3  14   0  24  28  48]
 [  1  17 136   0   1   0  22  10  47]
 [  1   1   0 588   1   0  25  44   3]
 [ 67   8   9   0 286  20   2   3  14]
 [ 27   0   0   0  24 235   0   0   1]
 [  2  10  12  21   2   0 126  54  36]
 [  1   7   6  37   0   0  78 322  19]
 [  5  25  73   3   5   0  54  22 280]]

### ExtraTreesClassifier ###
score.mean():  0.645966986738

0.692582417582
[[208  20   5   0  51  23   1   2  14]
 [ 20 335  35   3  18   0  27  35  43]
 [  0   6 138   0   1   0  19  10  53]
 [  0   0   0 585   1   0  26  44   1]
 [ 76   5   5   0 299  27   2   2  14]
 [ 29   1   0   0  24 238   0   0   0]
 [  0   9   7  18   0   0 117  53  35]
 [  1   6   5  43   1   0  76 312  12]
 [  6  25  77   3   4   0  68  27 289]]

###  BaggingClassifier ###
score.mean():  0.432598264792

0.441208791209
[[174  12  16   7  58  65   1   6  20]
 [ 22 237  30   5 115  18  32  44  72]
 [  5   3  67  17  13   0  11   9  40]
 [ 12   2   9 421  19   9  28  63  12]
 [ 45  84  35  17  95  20  41  15  52]
 [ 60  10   5   0  46 175   1   1   5]
 [  7   9  15  39   8   0  53  29  33]
 [  7   0  26 102  10   0  75 204  47]
 [  8  50  69  44  35   1  94 114 180]]
######################################################
(5460, 256) (3640, 256)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.183516483516
[[  0 321 428 231 116 357 283 225 177 380]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0  15   0   7 432  29   3  25  49   5]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   4   4  43  94  11   0  74 236  91]
 [  0   0   0   0   0   0   0   0   0   0]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.407417582418
[[163  21   9   4  58  63   6   9  10]
 [ 25 273  23   1 111  19  30  50  62]
 [  9   3  66  14  19   0  16   8  40]
 [ 80  13  24 472  68 179  88  80  48]
 [ 51  68  32  12 101  25  29  15  53]
 [  0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0]
 [  4   4  43  94  11   0  74 236  91]
 [  8  50  84  45  29   0  81  64 172]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.477747252747
[[169  30  16   8  51  26  12  12  14]
 [ 25 308  41  12 107  13  37  55  89]
 [  7   0  47  11  24   2  14   4  38]
 [ 43  23  33 505  86  24  73  53  42]
 [ 17  11  15   5  33   2  18  12  32]
 [ 56   9   1   0  47 214   1   4   2]
 [  0   0   1  10   1   0  23   4  12]
 [ 11  12  53  68  15   4  97 289  96]
 [ 12  39  74  23  33   1  49  29 151]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.541483516484
[[194  27  12   6  58  39   9  12  16]
 [ 19 295  17   4  70   9  29  46  48]
 [  5   1  73   7   8   0  10   6  37]
 [ 15   1  23 545  30   4  47  49  19]
 [ 57  62  47   9 185  21  56  34 103]
 [ 40   8   1   0  34 212   1   3   2]
 [  1   0   7  14   3   0  57  20  25]
 [  4  10  31  36   6   1  70 263  79]
 [  5  28  70  21   3   0  45  29 147]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.55768651239

0.59478021978
[[171  23   2   0  74  41   4   4  12]
 [ 23 251  23   6  18   1  29  31  40]
 [  9  31 132   0   6   0  21  11  73]
 [  2   1   2 561   1   0  24  42   4]
 [ 68  20   4   0 239  32   0   6   5]
 [ 45   1   0   0  38 211   0   0   3]
 [  2  37  25  31   6   0 107  76  72]
 [  1  26  11  38   7   0  81 267  41]
 [ 19  42  82   6   8   1  58  25 226]]

### RandomForestClassifier ###
score.mean():  0.633323367439

0.685989010989
[[209  12   2   0  59  29   3   2  11]
 [ 20 328  23   2  18   0  29  32  50]
 [  4  19 148   1   2   0  14   7  56]
 [  0   1   0 597   0   0  27  49   2]
 [ 65  14   4   0 288  20   3   5   7]
 [ 37   0   0   0  21 237   0   0   0]
 [  1  15  24  15   2   0 133  62  53]
 [  0   5   4  24   2   0  77 285  25]
 [  4  38  76   3   5   0  38  20 272]]

### ExtraTreesClassifier ###
score.mean():  0.633141430591

0.693681318681
[[201  14   4   0  50  25   2   2  15]
 [ 20 354  19   3  21   0  30  38  52]
 [  5  17 160   1   1   0  17  11  52]
 [  0   0   0 588   0   0  26  46   5]
 [ 72   9   1   1 291  27   2   4   5]
 [ 40   0   0   0  27 234   0   0   0]
 [  0  10  18   8   2   0 129  44  52]
 [  1   6   9  41   2   0  77 300  27]
 [  1  22  70   0   3   0  41  17 268]]

###  BaggingClassifier ###
score.mean():  0.423263638511

0.462087912088
[[155  20   9   7  54  59   5   7  10]
 [ 28 275  21   2 117  20  28  52  65]
 [  6   2  60   5  13   0   9   7  28]
 [ 16   1   8 436  28   4  23  49   5]
 [ 53  69  33  16  99  25  32  18  60]
 [ 66   8   1   0  30 178   3   2   3]
 [  2   3  21  34  10   0  61  26  38]
 [  3   7  41  92  12   0  79 237  86]
 [ 11  47  87  50  34   0  84  64 181]]
######################################################
(5460, 256) (3640, 256)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.177472527473
[[  0 307 427 241 116 359 279 227 170 407]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0  13   1  14 428  29   5  30  64   3]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   3   4  43  82  10   0  83 218  77]
 [  0   0   0   0   0   0   0   0   0   0]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.402747252747
[[177  21   5   7  58  58   5   5  22]
 [ 15 263  28   1 109  13  38  39  69]
 [ 10   2  65  18   6   0  13   7  39]
 [ 71  12  30 466  81 191  92  95  45]
 [ 35  82  38  18 102  22  39  19  60]
 [  0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0]
 [  3   4  43  82  10   0  83 218  77]
 [ 12  48  89  34  32   0  70  69 175]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.472802197802
[[167  20  11   7  44  32  10  14  23]
 [ 18 310  44   9 106  15  50  42  91]
 [  8   0  46   6   7   0  16   7  31]
 [ 41  24  42 511  93  18  76  64  46]
 [ 20  12  16  12  37   0  18   7  33]
 [ 45  10   1   0  54 216   0   2   2]
 [  0   0   0  10   0   0   5   2   3]
 [ 10  17  56  53  18   1 115 289 118]
 [ 14  39  82  18  39   2  50  25 140]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.533516483516
[[186  23   6   6  48  34   5  11  19]
 [ 11 283  25   2  87  11  29  37  58]
 [  7   1  63   9   2   0  12   7  28]
 [ 14   4  32 511  34   7  46  52  17]
 [ 53  63  42  17 169  11  47  21  74]
 [ 40   6   1   0  35 221   0   1   2]
 [  2   5   7  15   2   0  49  19  20]
 [  3   9  29  33   8   0  77 259  68]
 [  7  38  93  33  13   0  75  45 201]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.543216739111

0.599175824176
[[177  21   6   0  64  30   7   2  12]
 [  8 266  26   3  19   0  21  26  47]
 [  8  29 124   0   6   0  23  16  74]
 [  0   3   3 559   0   0  29  41   9]
 [ 61  19   8   1 247  36   5   4  17]
 [ 44   1   0   0  30 213   0   0   2]
 [  6  24  30  21  11   0 119  74  64]
 [  5  20  10  33   6   0  73 254  40]
 [ 14  49  91   9  15   5  63  35 222]]

### RandomForestClassifier ###
score.mean():  0.626720189509

0.689835164835
[[208  27   8   0  69  26   7   4  17]
 [ 14 327  25   5  16   0  28  34  51]
 [  3  15 153   3   1   0  18   5  54]
 [  0   1   0 568   0   0  15  47   2]
 [ 63  14   5   0 286  14   6   0   9]
 [ 31   0   0   0  23 244   0   0   1]
 [  0   7  23  20   1   0 134  46  35]
 [  0  14   6  28   1   0  80 300  27]
 [  4  27  78   2   1   0  52  16 291]]

### ExtraTreesClassifier ###
score.mean():  0.631856859264

0.692032967033
[[201  24   8   0  70  25   3   3  18]
 [ 15 341  23   2  18   0  37  33  61]
 [  3  15 174   0   0   0  11   4  57]
 [  0   1   0 582   0   0  25  51   3]
 [ 69  10   4   0 286  21   4   2  11]
 [ 33   0   0   0  22 238   0   0   0]
 [  0  11   9  13   0   0 131  47  47]
 [  1  13   5  25   1   0  78 301  25]
 [  1  17  75   4   1   0  51  11 265]]

###  BaggingClassifier ###
score.mean():  0.41758741426

0.468681318681
[[175  19   3   8  56  61   5   8  20]
 [ 16 269  27   2 107  14  38  40  68]
 [  6   2  56  12   5   0  17   6  38]
 [ 12   1  16 438  26   5  28  62   5]
 [ 43  82  38  16 110  25  36  19  59]
 [ 51   4   4   0  26 179   0   1   6]
 [  2   6  16  35  22   0  64  19  31]
 [  3   4  45  78  12   0  84 235  80]
 [ 15  45  93  37  34   0  68  62 180]]
######################################################
(5460, 256) (3640, 256)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.192582417582
[[  0 324 402 235 112 369 277 223 170 396]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   7   0  13 460  23   4  20  39  15]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   1   2  39  86  10   0  87 241  85]
 [  0   0   0   0   0   0   0   0   0   0]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.420879120879
[[175  15   8   5  65  60   6   3  16]
 [ 18 277  25   3 115  20  45  46  60]
 [ 10   6  72  13  14   0  16  15  47]
 [ 83  10  30 502  72 181  76  71  62]
 [ 41  49  30  13  97  20  33  12  58]
 [  0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0]
 [  1   2  39  86  10   0  87 241  85]
 [  4  45  83  36  29   0  67  62 168]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.476923076923
[[178  19  18  13  43  30  11   8  19]
 [ 23 292  41   8 108  19  45  53  85]
 [  8   1  44   6  12   2  18   7  32]
 [ 35  29  45 516  85  19  61  50  60]
 [ 23   7  12   8  40   1  24  11  37]
 [ 49  10   3   0  53 210   2   1   2]
 [  0   0   1   8   0   0   7   0   1]
 [  7  11  46  81  21   0 113 295 106]
 [  9  35  77  18  40   0  49  25 154]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.527472527473
[[166  16   9   4  39  34   5   4  13]
 [ 16 273  22   5  65  12  30  43  46]
 [  5   3  72   7   6   1  16   8  31]
 [  9   5  26 553  32   4  34  40  28]
 [ 86  69  56  23 197  24  88  54 133]
 [ 47   5   2   0  40 206   0   0   1]
 [  0   1   5   9   4   0  33   7  16]
 [  3   4  25  41  10   0  78 270  78]
 [  0  28  70  16   9   0  46  24 150]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.541568196819

0.615659340659
[[188  21   7   0  69  28   8   2  13]
 [  8 236  19   5  21   0  25  21  42]
 [  6  32 147   4   9   0  26  13  79]
 [  2   7   0 577   0   0  26  28   5]
 [ 65  12   2   0 246  35   4   5  13]
 [ 48   1   0   0  31 217   0   0   0]
 [  7  21  20  28   2   0 111  69  54]
 [  2  28  18  41  10   0  79 270  41]
 [  6  46  74   3  14   1  51  42 249]]

### RandomForestClassifier ###
score.mean():  0.619939670153

0.701923076923
[[217  16   9   0  73  17   7   1  19]
 [ 12 319  25   4  15   0  36  30  48]
 [  2  12 169   0   6   0  21   5  68]
 [  0   1   0 604   0   0  28  40   5]
 [ 69   7   4   0 277  26   3   1   8]
 [ 28   0   0   0  25 238   0   0   0]
 [  2  15  15  18   1   0 134  43  42]
 [  0  11   6  32   0   0  63 312  21]
 [  2  23  59   0   5   0  38  18 285]]

### ExtraTreesClassifier ###
score.mean():  0.63222192655

0.701648351648
[[196  12   3   0  73  22   4   0  15]
 [ 16 329  26   2  15   0  37  31  44]
 [  4   6 181   0   6   0  20   9  64]
 [  0   0   0 601   0   0  24  37   1]
 [ 70   8   3   0 277  17   2   2  11]
 [ 39   0   0   0  23 242   0   0   1]
 [  1  17   9  18   0   0 126  43  43]
 [  2   8   9  37   2   0  77 303  18]
 [  4  24  56   0   6   0  40  25 299]]

###  BaggingClassifier ###
score.mean():  0.42196704116

0.464285714286
[[177  16   9   6  60  61   5   3  15]
 [ 19 277  25   4 121  21  46  45  59]
 [  8   0  66  10  12   0  14  10  47]
 [  7   2   9 441  26   4  17  36  12]
 [ 44  49  29  10  93  21  35  14  57]
 [ 71   7   4   2  35 174   1   0   4]
 [  1   7  18  49  14   0  55  37  46]
 [  2   2  42  98  14   0  89 241  90]
 [  3  44  85  38  27   0  68  64 166]]
######################################################
(5460, 256) (3640, 256)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.180769230769
[[  0 328 399 211 125 341 281 240 208 389]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0  19   1  14 425  21   7  26  47  14]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   3   2  38  83   9   0  99 233  77]
 [  0   0   0   0   0   0   0   0   0   0]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.404395604396
[[175   7   6   5  42  56   6   0  13]
 [ 18 255  17   2 106  17  41  50  50]
 [ 14   6  67  17  14   0  19  12  47]
 [ 82  17  36 462  65 192  83  71  59]
 [ 54  78  32  16 104  22  43  20  58]
 [  0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0]
 [  3   2  38  83   9   0  99 233  77]
 [  4  37  67  48  31   1  74 102 176]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.479945054945
[[175  13  12   8  41  25  12   4  18]
 [ 21 294  35  11 104  15  43  64  63]
 [  6   3  52   6   8   1  17   8  34]
 [ 49  24  46 494  85  21  76  50  59]
 [ 22   7  15  16  40   1  34  17  33]
 [ 53  16   2   0  48 224   2   1   3]
 [  0   0   1   6   0   0   4   3   5]
 [ 11  11  46  71  15   0 127 300 101]
 [ 13  34  54  21  30   1  50  41 164]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.529945054945
[[197  14  11   4  39  35   9   4  17]
 [ 13 281  17   1  91  11  31  53  37]
 [  8   5  74  14   5   0  16   9  40]
 [ 20   3  44 544  36   8  68  59  45]
 [ 63  51  36  15 129  16  51  26  67]
 [ 40  11   1   0  41 218   1   1   1]
 [  0   4   4   4   1   0  35  13  29]
 [  3   4  23  34   8   0  97 279  72]
 [  6  29  53  17  21   0  57  44 172]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.554391213298

0.596978021978
[[176  12   3   0  63  44   5   2  11]
 [ 29 236  12   3  20   0  22  31  36]
 [  6  27 122   4   3   1  25  16  82]
 [  0   0   2 551   1   0  36  35   7]
 [ 74  20   3   1 228  26   6   3   9]
 [ 47   1   0   0  35 217   0   0   0]
 [  2  30  28  33   1   0 113  73  58]
 [  3  25  17  36   6   0  94 281  28]
 [ 13  51  76   5  14   0  64  47 249]]

### RandomForestClassifier ###
score.mean():  0.643402881078

0.681043956044
[[196  13   2   0  50  31   9   1  16]
 [ 17 316  25   4  12   0  34  38  32]
 [  3  11 155   0   3   0  20   6  81]
 [  0   1   0 574   0   0  28  45   2]
 [ 91  14   2   0 269  18   6   1   8]
 [ 39   0   0   0  29 239   0   0   0]
 [  1  12  16   6   1   0 133  44  42]
 [  1   4   4  45   2   0  88 325  27]
 [  2  31  59   4   5   0  47  28 272]]

### ExtraTreesClassifier ###
score.mean():  0.644496949625

0.681318681319
[[199  15   5   0  51  31   3   2  14]
 [ 22 320  24   3  20   0  35  39  37]
 [  6  10 148   0   4   0  19  11  72]
 [  0   0   1 584   0   0  31  42   4]
 [ 79  10   2   0 262  17   4   0   4]
 [ 40   0   0   0  27 240   0   0   0]
 [  0  12  15  13   1   0 128  55  47]
 [  1  12   6  32   2   0  97 323  26]
 [  3  23  62   1   4   0  48  16 276]]

###  BaggingClassifier ###
score.mean():  0.432225516895

0.457142857143
[[174   7   6   6  46  53   4   1  13]
 [ 18 257  19   3 111  19  41  54  63]
 [ 11   7  64  16   9   1  16  13  40]
 [ 19   0  11 420  24   8  22  43  15]
 [ 58  78  30  13 101  23  38  18  51]
 [ 57   8   6   0  25 184   1   0   7]
 [  4   9  13  44  16   0  53  26  40]
 [  3   2  44  85  10   0 111 238  78]
 [  6  34  70  46  29   0  79  95 173]]
######################################################
(5460, 256) (3640, 256)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.18956043956
[[  0 299 406 263 113 374 267 246 195 382]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0  19   0   9 447  33   7  24  61   7]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   2   2  26  70   8   0  75 243  62]
 [  0   0   0   0   0   0   0   0   0   0]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.406593406593
[[149  15   6   4  49  76   4   3  19]
 [ 22 266  26   4 117  12  32  53  58]
 [ 12   4  77  20  18   0  21  13  46]
 [ 73  19  33 481  83 169  81 101  55]
 [ 55  53  33  16 102  17  35  14  49]
 [  0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0]
 [  2   2  26  70   8   0  75 243  62]
 [  7  49  97  35  38   0  97  72 162]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.473901098901
[[156  23  15   7  43  44   7   6  23]
 [ 25 295  34  12 115  15  41  53  79]
 [ 15   1  76  14  21   1  23  11  43]
 [ 44  22  39 493  92  27  66  61  39]
 [ 27   8  24  10  38   2  25  14  31]
 [ 35  13   2   0  49 181   0   1   4]
 [  0   0   4  24   1   0  29  16  17]
 [  7   6  20  54  12   4  84 294  52]
 [ 11  40  84  16  44   0  70  43 163]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.516758241758
[[160  19   7   3  47  56   4   5  16]
 [ 19 291  21   4  96   8  33  54  51]
 [ 14   2 100  15  20   0  22  12  53]
 [ 18   1  24 540  42   9  47  57  27]
 [ 60  46  49  11 138  17  51  30  79]
 [ 40  12   2   0  39 183   0   1   5]
 [  1   2  12   9   1   0  47  27  26]
 [  4   3  14  30   8   1  75 274  46]
 [  4  32  69  18  24   0  66  39 148]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.550167471871

0.608241758242
[[180  26  11   0  76  25   6   1  14]
 [ 19 251  31   3  30   1  21  16  44]
 [  3  29 136   3   1   0  29  15  77]
 [  0   2   4 544   4   0  22  34   6]
 [ 56  12   8   0 245  39   8   4   7]
 [ 44   0   0   0  30 208   0   0   0]
 [  4  25  28  36  10   0 129  95  50]
 [  2  25   9  35   4   0  69 296  28]
 [ 12  38  71   9  15   1  61  38 225]]

### RandomForestClassifier ###
score.mean():  0.635884781925

0.686263736264
[[174  17  11   0  58  26  11   1  14]
 [ 22 329  28   5  21   0  26  31  53]
 [  2  14 168   2   3   0  21   6  63]
 [  0   0   0 581   0   0  34  52   5]
 [ 81   9   7   0 298  18   5   4   8]
 [ 37   0   0   0  29 229   0   0   0]
 [  1  13   8  11   1   0 131  52  30]
 [  1   7   4  29   1   0  65 332  22]
 [  2  19  72   2   4   1  52  21 256]]

### ExtraTreesClassifier ###
score.mean():  0.641925635242

0.680494505495
[[191  16  10   0  73  24   5   3  15]
 [ 25 339  25   5  18   0  29  40  52]
 [  2  12 155   2   1   0  18   8  59]
 [  0   0   0 582   2   0  27  56   4]
 [ 68   5   8   0 283  25   6   1  10]
 [ 33   0   0   0  31 225   0   0   0]
 [  1   8   6  13   2   0 125  60  25]
 [  0   8   5  24   0   0  77 314  23]
 [  0  20  89   4   5   0  58  17 263]]

###  BaggingClassifier ###
score.mean():  0.431309336969

0.459340659341
[[149  14   8   5  47  72   3   4  16]
 [ 20 277  30   4 125  13  40  53  63]
 [ 10   3  65  17  10   0  18   9  43]
 [ 19   0  11 449  34   7  20  56  10]
 [ 54  51  29  14  94  16  31  14  46]
 [ 52  12   5   0  42 165   2   1  10]
 [  4   8  19  34  11   0  58  37  38]
 [  4   2  30  70  13   0  75 246  56]
 [  8  41 101  37  39   1  98  79 169]]
######################################################
(5460, 256) (3640, 256)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.186813186813
[[  0 290 419 245 105 372 262 227 177 409]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0  19   0   6 455  37   4  31  51  10]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   6   6  41  89  13   0  74 225  67]
 [  0   0   0   0   0   0   0   0   0   0]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.412912087912
[[158  14  16   7  70  64   1   3   7]
 [ 19 279  18   3 107  11  46  42  79]
 [ 14   2  74  19  13   0  10  11  38]
 [ 70  26  25 496  99 172  94  83  52]
 [ 43  55  34   8  93  19  34  12  65]
 [  0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0]
 [  6   6  41  89  13   0  74 225  67]
 [  5  43  84  27  27   0  73  77 178]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.472252747253
[[171  43  34   8  92  28  35  21  43]
 [ 26 288  36  10  82   7  38  49 100]
 [ 12   0  46  10  16   1   8   4  25]
 [ 40  27  28 529  89  15  69  45  40]
 [  7   3  17   2  38   1  16   2  21]
 [ 39  18   2   0  61 212   0   1   0]
 [  0   0   0   7   0   0   9   3   0]
 [ 12  20  69  75  20   2 112 305 136]
 [  8  26  60   8  24   0  45  23 121]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.53021978022
[[167  15  19   6  55  30   4   9  10]
 [ 23 317  20   6  95   7  51  52  78]
 [ 10   0  70  10   7   0   7   7  34]
 [ 20   1  17 544  37   5  43  34  25]
 [ 54  50  58  13 165  18  68  23 103]
 [ 33  16   1   0  44 206   0   1   0]
 [  1   4   7  12   3   0  34  14  14]
 [  4   7  36  47   8   0  85 285  80]
 [  3  15  64  11   8   0  40  28 142]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.562995000888

0.595054945055
[[161  26   4   1  75  46   3   3  16]
 [ 13 266  21   2  22   0  40  29  44]
 [  5  26 129   2   9   0  25  16  85]
 [  2   5   2 558   0   0  23  51   4]
 [ 71  14   6   1 255  28   7   5  11]
 [ 36   0   0   0  44 191   0   0   1]
 [ 10  29  23  35   8   0 117  48  66]
 [  5  22  16  45   3   0  80 270  40]
 [ 12  37  91   5   6   1  37  31 219]]

### RandomForestClassifier ###
score.mean():  0.626915406081

0.692032967033
[[216  17   6   0  92  25   5   1  14]
 [  9 349  25   3  18   0  27  27  63]
 [  2  12 159   2   1   0  22   9  61]
 [  1   0   1 600   0   0  25  42   3]
 [ 51  11   5   0 271  17   5   3  12]
 [ 26   0   0   0  33 224   0   0   0]
 [  4   8   7  19   3   0 132  55  42]
 [  1  11  11  24   1   0  71 298  21]
 [  5  17  78   1   3   0  45  18 270]]

### ExtraTreesClassifier ###
score.mean():  0.628016017871

0.690384615385
[[206  16   7   0  73  25   2   2  10]
 [ 15 347  32   2  28   0  27  26  63]
 [  5  11 158   1   1   0  23   8  66]
 [  1   0   0 602   0   0  15  51   5]
 [ 57   9   2   0 280  14   6   2  14]
 [ 28   0   0   0  35 227   0   0   1]
 [  2   7  14  11   2   0 126  44  36]
 [  0  14   7  30   1   0  82 299  23]
 [  1  21  72   3   2   0  51  21 268]]

###  BaggingClassifier ###
score.mean():  0.417573350981

0.466208791209
[[159  17  21   6  71  67   3   3   9]
 [ 21 275  22   3 111  12  45  44  90]
 [ 12   2  65  19  13   0   8  11  27]
 [ 21   0   4 460  38   4  26  48  12]
 [ 42  59  33   7  97  20  30  14  58]
 [ 50  19   4   0  46 163   3   1   5]
 [  0   7  18  40  10   0  62  32  34]
 [  6   7  41  83  12   0  76 234  69]
 [  4  39  84  31  24   0  79  66 182]]
######################################################
(5460, 256) (3640, 256)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.172252747253
[[  0 314 404 254 122 365 295 228 187 402]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   7   0  11 410  18   5  33  54  11]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0]
 [  0   2   1  49  92   5   0  73 217  81]
 [  0   0   0   0   0   0   0   0   0   0]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.393406593407
[[173  10   7   5  66  63   4   8  13]
 [ 26 260  32   4 114   9  30  50  81]
 [  8   4  75  24  15   0  13  14  48]
 [ 63  19  35 451  56 203  96  87  52]
 [ 39  69  32  10  95  24  46  17  58]
 [  0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0]
 [  2   1  49  92   5   0  73 217  81]
 [ 12  42  84  38  37   1  72  65 161]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.479395604396
[[187  25  15   7  75  33  14   9  23]
 [ 37 295  45  15 100  12  48  67 108]
 [  9   1  54   5  16   3  12   7  29]
 [ 26  28  47 495  58  20  87  46  42]
 [  6   7  15   9  29   0  18   7  21]
 [ 46  10   2   0  50 231   1   0   2]
 [  0   0   5  18   0   0  15   8  13]
 [  4   9  58  58  15   0  84 286 103]
 [  8  30  73  17  45   1  55  28 153]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.521703296703
[[193  14   9   3  56  40   5   9  12]
 [ 27 293  20   8  94   7  24  57  71]
 [  8   6  88  17  15   0  13   9  52]
 [ 13   6  38 518  17   5  70  57  26]
 [ 40  45  33  10 111  19  52  18  56]
 [ 35   7   1   0  47 228   1   0   2]
 [  1   4  15  14   2   0  44  18  30]
 [  0   5  33  38  12   0  68 259  80]
 [  6  25  77  16  34   1  57  31 165]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.544141989836

0.595879120879
[[165  19   3   0  69  29   8   4   9]
 [ 19 251  23   2  21   0  26  21  58]
 [  5  21 141   2   5   0  20  14  82]
 [  1   4   0 508   1   0  35  39   6]
 [ 58  14   5   0 246  33   5   3   9]
 [ 52   0   0   0  25 238   0   0   2]
 [  6  31  35  34   4   0 123  66  77]
 [  3  24  22  72   7   0  77 282  36]
 [ 14  41  85   6  10   0  40  29 215]]

### RandomForestClassifier ###
score.mean():  0.62398472681

0.682142857143
[[201  17   5   0  65  27   6   4  15]
 [ 18 330  28   3  17   0  20  27  60]
 [  5  10 149   0   1   0  20   7  58]
 [  0   1   0 567   0   0  24  46   7]
 [ 54  10   7   0 280  21   7   4  11]
 [ 38   0   0   0  18 252   0   0   0]
 [  1   9  20   3   4   0 141  51  55]
 [  2  10   8  47   2   0  79 298  23]
 [  4  18  97   4   1   0  37  21 265]]

### ExtraTreesClassifier ###
score.mean():  0.635521994695

0.687362637363
[[181  10   9   0  51  23   7   0  12]
 [ 24 344  27   2  27   1  30  37  55]
 [  3   9 158   0   2   0  15   5  57]
 [  0   0   0 553   0   0  17  46   6]
 [ 70  12   5   0 276  21   5   5  13]
 [ 38   0   0   0  26 255   0   0   0]
 [  1   9  15  18   3   0 148  46  45]
 [  1   3  10  49   2   0  76 305  24]
 [  5  18  90   2   1   0  36  14 282]]

###  BaggingClassifier ###
score.mean():  0.424167533627

0.454120879121
[[173  13   9   7  64  68   5   5  16]
 [ 23 268  29   5 113  11  36  56  81]
 [  8   8  67  17  12   0  14   7  46]
 [  7   0  14 411  20   5  32  53   9]
 [ 39  69  33  11  91  21  36  13  55]
 [ 58   5   2   0  34 194   5   2   2]
 [  1   7  20  32   7   0  55  23  32]
 [  3   1  52 100  11   0  79 233  92]
 [ 11  34  88  41  36   1  72  66 161]]
######################################################
######################################################
comb 0 :
[ 0.18681319  0.18351648  0.17362637  0.18351648  0.17747253  0.19258242
  0.18076923  0.18956044  0.18681319  0.17225275]
0.182692307692
comb 1 :
[ 0.40796703  0.39752747  0.39038462  0.40741758  0.40274725  0.42087912
  0.4043956   0.40659341  0.41291209  0.39340659]
0.404423076923
comb 2 :
[ 0.46675824  0.47142857  0.45604396  0.47774725  0.4728022   0.47692308
  0.47994505  0.4739011   0.47225275  0.4793956 ]
0.47271978022
comb 3 :
[ 0.52802198  0.50714286  0.50164835  0.54148352  0.53351648  0.52747253
  0.52994505  0.51675824  0.53021978  0.5217033 ]
0.523791208791
comb 4 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 5 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 6 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 7 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 8 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 9 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 0 :
[ 0.60659341  0.60192308  0.60714286  0.59478022  0.59917582  0.61565934
  0.59697802  0.60824176  0.59505495  0.59587912]
0.602142857143
ens 1 :
[ 0.68736264  0.68901099  0.69093407  0.68598901  0.68983516  0.70192308
  0.68104396  0.68626374  0.69203297  0.68214286]
0.688653846154
ens 2 :
[ 0.69423077  0.69615385  0.69258242  0.69368132  0.69203297  0.70164835
  0.68131868  0.68049451  0.69038462  0.68736264]
0.690989010989
ens 3 :
[ 0.45851648  0.44725275  0.44120879  0.46208791  0.46868132  0.46428571
  0.45714286  0.45934066  0.46620879  0.45412088]
0.457884615385
ens 4 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 5 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 6 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 7 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 8 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 9 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
