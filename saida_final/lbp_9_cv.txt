Starting read from Train file...
(9100, 75)
train.shape = (9100, 74)
train_labels.shape = (9100, 1)
(5460, 74) (3640, 74)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.792032967033
[[  0  64  75  59  55  74  23  61   2  81]
 [  0 249   7   0   2  20   9   0   0   2]
 [  0   4 307   2  12   0   0   2   0  25]
 [  0   3   0 206   0   1   0  34   2   4]
 [  0   0   4   0 568   1   0   0   0   4]
 [  0   8   0   0   0 292   9   1   1   0]
 [  0  12   0   0   0  20 242   0   0   0]
 [  0   1   0  13   1   0   0 211  10   4]
 [  0   0   0   1   0   0   0  17 439   0]
 [  0   0  15   2   8   1   0   1   0 369]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.853296703297
[[285  15   2  11  23  17   6   0   6]
 [  6 324   7  38   1   0  12   0  31]
 [  3   0 242   3   2   0  69   4   7]
 [  0   4   1 569   1   0   0   0   4]
 [ 33   4   4   0 358  24   5   1   1]
 [ 12   0   0   0  20 242   0   0   0]
 [  1   0  13   1   0   0 211  10   4]
 [  0   0   1   0   0   0  17 439   0]
 [  1  61  13  24   4   0   7   0 436]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.687912087912
[[263  17   2  40  26  43  21   1   3]
 [  7 240  13  26   6   0  11   0  34]
 [  5   0 121   1  10   1  63   4   6]
 [  5  42  25 559  16   0  15   0  67]
 [ 23  18   8   8 282  33  19  57   9]
 [ 13   0   0   0  21 202   0   0   0]
 [  1   0   7   0   0   0 115   8   0]
 [ 22   6  43   0  45   4  65 382  30]
 [  2  85  64  12   3   0  18   2 340]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.598626373626
[[124   2   0   2   8   2   1   0   1]
 [  3 210   2  10   0   0   2   0  23]
 [  1   1 143   1   3   0  37   2   6]
 [ 16 100  76 570  22   0  68   8 128]
 [192  85  37  57 375 280  44  81  49]
 [  0   0   0   0   0   0   0   0   0]
 [  0   0   3   0   0   0 127   9   0]
 [  5   0  18   0   1   1  48 354   6]
 [  0  10   4   6   0   0   0   0 276]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.612451684428

0.666208791209
[[189  10   8   9  47  26  18   2   5]
 [ 18 242  21  59   9   3  14   0  87]
 [  9  13 154   5  15   3  56  14  40]
 [ 17  64  12 516   2   0   6   1  60]
 [ 58   8  16   1 252  33   5   4   8]
 [ 27   2   0   0  53 215   0   0   0]
 [  9   3  40   7  17   0 174  29   9]
 [  1   0   3   0   1   1  40 403   0]
 [ 13  66  29  49  13   2  14   1 280]]

### RandomForestClassifier ###
score.mean():  0.69670069514

0.766483516484
[[250   8   9   3  58  20   9   0   4]
 [  7 301  10  45   0   1   8   0  77]
 [  7   8 197   0   5   1  64   6  31]
 [  3  43   3 571   1   0   4   0  33]
 [ 45   2   9   0 304  30   3   4   3]
 [ 20   1   0   0  30 230   1   0   0]
 [  3   5  34   4   5   0 199  39   8]
 [  0   0   2   0   0   1  29 405   0]
 [  6  40  19  23   6   0  10   0 333]]

### ExtraTreesClassifier ###
score.mean():  0.705318043791

0.766758241758
[[264  13   6   7  49  24  10   0   6]
 [ 11 311  14  33   1   0   7   0  84]
 [  4   1 183   0   9   1  72   7  36]
 [  1  35   2 582   2   0   6   0  40]
 [ 33   2  10   0 303  37   7   3   2]
 [ 25   1   0   0  36 221   0   0   0]
 [  3   1  36   1   4   0 197  29   5]
 [  0   0   3   0   0   0  24 415   1]
 [  0  44  29  23   5   0   4   0 315]]

###  BaggingClassifier ###
score.mean():  0.783505860068

0.817307692308
[[266  11   3  11  52  19   1   0   5]
 [ 11 329   7  29   2   0  16   0  53]
 [  8   6 228   6   7   0  63   7  19]
 [  0  11   0 575   1   0   1   0  13]
 [ 22   4   1   0 305  14   3   1   0]
 [ 33   0   1   0  37 250   0   0   0]
 [  1   0  34   1   1   0 225  38  10]
 [  0   0   0   0   0   0  16 408   0]
 [  0  47   9  24   4   0   2   0 389]]
######################################################
(5460, 74) (3640, 74)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.789010989011
[[  0  58  68  61  43  92  22  48   1  98]
 [  0 273   5   1   2  37  10   1   0   2]
 [  0   4 307   0   6   0   0   4   0  23]
 [  0   3   0 219   0   0   0  25   2   4]
 [  0   0   7   0 566   2   0   0   0   6]
 [  0   9   0   0   0 260  13   2   1   0]
 [  0   9   0   0   0  16 223   0   0   0]
 [  0   2   0  18   1   0   0 225   7   0]
 [  0   0   0   2   0   0   0  27 455   0]
 [  0   0  16   3   6   0   0   1   0 344]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.856318681319
[[294  10   6   9  41  20   3   0   6]
 [  5 325   6  28   1   0  16   0  31]
 [  3   0 255   3   1   0  53   3   6]
 [  0   7   0 568   2   0   0   0   6]
 [ 42   7   2   0 345  25   6   2   0]
 [  9   0   0   0  16 223   0   0   0]
 [  2   0  18   1   0   0 225   7   0]
 [  0   0   2   0   0   0  27 454   0]
 [  3  54  15  15   1   0   3   0 428]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.698626373626
[[274  11   5  39  35  43  16   1   2]
 [ 11 247  26  18   7   0  19   0  31]
 [  5   0 138   1  12   0  54   3   6]
 [  9  43  21 550  14   0  15   0  77]
 [ 22  18   8   7 271  45  21  50   7]
 [  8   0   0   0  18 179   0   0   0]
 [  1   0   6   0   1   0 139   3   0]
 [ 26   2  56   0  46   1  61 409  18]
 [  2  82  44   9   3   0   8   0 336]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.58543956044
[[145   2   1   1  18   2   1   0   0]
 [  8 184   1   3   1   0   4   0  18]
 [  1   0 133   0   0   0  18   2   6]
 [ 29 115  90 589  30   0 111  11 162]
 [167  89  45  27 352 266  40  77  42]
 [  0   0   0   0   0   0   0   0   0]
 [  1   0   1   0   0   0 113   6   0]
 [  7   1  25   0   5   0  45 370   4]
 [  0  12   8   4   1   0   1   0 245]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.609341760986

0.672527472527
[[222   9  21   8  54  25   8   2   6]
 [ 14 206  11  42   6   1   6   0  56]
 [ 14  11 148   5  10   0  42   4  31]
 [  6  60  12 498   3   0   7   1  45]
 [ 52  17   8   6 269  41   7   8   9]
 [ 30   8   3   0  41 197   1   0   0]
 [ 15   5  54  10  13   1 196  41  21]
 [  0   0   8   1   0   0  57 406   3]
 [  5  87  39  54  11   3   9   4 306]]

### RandomForestClassifier ###
score.mean():  0.701468994079

0.770879120879
[[274   6  15   3  67  17  10   0   5]
 [ 19 305   7  39   0   0   7   0  56]
 [  7   2 197   0   9   0  39   7  28]
 [  2  43   0 554   3   0   2   0  41]
 [ 37   2  13   1 282  36  10   2   1]
 [  9   3   0   0  38 215   0   0   0]
 [  7   3  39   2   4   0 230  43  11]
 [  0   0   2   0   0   0  30 414   0]
 [  3  39  31  25   4   0   5   0 335]]

### ExtraTreesClassifier ###
score.mean():  0.702569302036

0.770054945055
[[277  11  14   5  70  29   7   1   8]
 [ 14 287  13  31   3   2   9   0  58]
 [ 10   6 198   2   6   0  31   2  25]
 [  1  50   2 560   2   0   2   0  37]
 [ 30   2   8   0 283  28  11   2   2]
 [ 18   1   1   0  34 209   0   0   0]
 [  3   0  36   0   5   0 229  36  11]
 [  0   0   2   0   0   0  36 424   0]
 [  5  46  30  26   4   0   8   1 336]]

###  BaggingClassifier ###
score.mean():  0.784972458014

0.818681318681
[[293  10   4   9  68  21   1   0   5]
 [ 11 328   4  24   3   0  14   0  60]
 [  6   4 247   5   9   0  49   6  22]
 [  0  13   0 570   2   0   0   0  16]
 [ 23   6   0   0 282  18   5   2   0]
 [ 21   0   2   0  41 229   0   0   0]
 [  3   0  37   2   0   0 241  32  10]
 [  0   0   0   0   0   0  22 426   0]
 [  1  42  10  14   2   0   1   0 364]]
######################################################
(5460, 74) (3640, 74)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.795054945055
[[  0  58  65  51  46  85  28  52   0  94]
 [  0 249   4   4   4  29  12   1   0   3]
 [  0   1 310   0   6   0   0   2   0  17]
 [  0   3   0 199   0   1   0  31   2   7]
 [  0   0   6   0 575   1   0   0   0   6]
 [  0   9   0   0   0 278  11   1   0   1]
 [  0   5   0   0   0  19 219   0   0   0]
 [  0   1   0  24   0   0   0 217   9   2]
 [  0   0   0   1   0   0   0  18 480   0]
 [  0   0  15   2   6   1   0   2   0 367]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.859340659341
[[276  10   9   9  39  28   2   0   9]
 [  1 333   7  28   0   0  10   0  22]
 [  3   0 229   4   1   1  63   2   8]
 [  0   6   0 577   1   0   1   0   6]
 [ 40   3   2   1 352  22   7   2   3]
 [  5   0   0   0  19 219   0   0   0]
 [  1   0  24   0   0   0 217   9   2]
 [  0   0   1   0   0   0  18 478   0]
 [  0  48   9  18   2   0   6   0 447]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.716483516484
[[266  17  11  34  52  48  24   1   6]
 [  7 259  34  14  10   1  14   0  33]
 [  3   0 127   0   9   1  56   3  10]
 [  9  41  20 571  21   0  15   0  71]
 [ 27  14   5   4 280  22  20  66   8]
 [  6   0   0   0  21 194   0   0   0]
 [  1   0   8   0   1   0 133   7   0]
 [  6   0  35   0  19   4  51 414   5]
 [  1  69  41  14   1   0  11   0 364]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.673351648352
[[213   4   7   2  22  21   4   0   1]
 [  2 226   5   3   2   0   0   0  23]
 [  3   0 148   0   2   1  23   3   6]
 [ 33 110  80 613  36   0 128  38 163]
 [ 70  43  24  12 341  86  44  72  36]
 [  4   0   0   0  11 162   0   0   0]
 [  1   0   5   0   0   0 110   7   0]
 [  0   0   9   0   0   0  15 371   1]
 [  0  17   3   7   0   0   0   0 267]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.60256249571

0.667857142857
[[197  10  14  11  55  23  14   1   7]
 [  9 217   9  53   5   0  10   0  69]
 [ 12  12 153   5   7   1  48  13  43]
 [  5  51   3 500   4   1   8   1  58]
 [ 63   6  13   2 260  29  10   4   5]
 [ 25   4   0   0  49 214   0   0   2]
 [  8   9  46   8  13   0 183  55  21]
 [  1   0  19   0   6   0  41 415   0]
 [  6  91  24  58  15   2  10   2 292]]

### RandomForestClassifier ###
score.mean():  0.693778103814

0.762087912088
[[246  13  14   6  45  24   6   0   5]
 [  5 288   6  44   3   0   7   0  67]
 [  8   1 193   0  11   1  53   6  35]
 [  6  49   0 560   3   0  10   0  47]
 [ 38   2   6   0 303  40  11   2   7]
 [ 17   2   0   0  36 205   0   0   0]
 [  3   2  36   0   5   0 205  38   7]
 [  0   0   3   0   0   0  26 445   0]
 [  3  43  23  27   8   0   6   0 329]]

### ExtraTreesClassifier ###
score.mean():  0.700000085261

0.765659340659
[[254  11   7   3  53  26  15   1   9]
 [  8 286  10  38   2   0   7   0  61]
 [  6   2 196   3  11   1  58   3  39]
 [  1  46   2 567   4   0   4   0  45]
 [ 35   5   6   0 303  38   8   2   0]
 [ 17   0   1   0  33 204   0   0   0]
 [  3   1  36   1   4   0 196  38   9]
 [  0   0   4   0   0   1  29 447   0]
 [  2  49  19  25   4   0   7   0 334]]

###  BaggingClassifier ###
score.mean():  0.783142553457

0.818406593407
[[266   8   6   8  64  25   1   1   6]
 [  2 321   5  21   1   0   9   0  42]
 [  9   5 218   7  11   1  61   8  26]
 [  0  22   1 583   3   0   1   0  22]
 [ 26   3   0   1 298  19   6   1   2]
 [ 21   0   0   0  36 225   0   0   0]
 [  2   0  44   2   0   0 231  38   5]
 [  0   0   0   0   0   0  13 443   0]
 [  0  41   7  15   1   0   2   0 394]]
######################################################
(5460, 74) (3640, 74)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.791483516484
[[  0  53  69  65  69  77  21  55   0  99]
 [  0 241   2   2   1  34   6   0   0   1]
 [  0   2 295   0  11   0   0   2   0  16]
 [  0   3   0 219   0   0   0  35   2   4]
 [  0   0   4   0 532   2   0   0   0   4]
 [  0  10   0   0   0 270   9   0   1   1]
 [  0   7   0   0   0  20 250   0   0   0]
 [  0   2   0  21   1   0   0 241   3   3]
 [  0   0   0   1   0   0   0  21 464   0]
 [  0   1  10   2   5   0   0   2   0 369]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.857692307692
[[266  10   3   8  39  18   4   0   6]
 [  2 316   8  47   0   0  13   0  23]
 [  4   0 257   4   0   0  64   2   4]
 [  0   4   0 535   2   0   0   0   4]
 [ 36   3   4   0 340  18   4   3   2]
 [  7   0   0   0  20 250   0   0   0]
 [  2   0  21   1   0   0 241   3   3]
 [  0   0   1   0   0   0  21 462   0]
 [  2  47  16  24   2   0   9   0 455]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.7
[[256  12  11  36  62  40  21   0   3]
 [  7 237  33  33   6   1  17   0  49]
 [  5   1 146   2  12   0  70   2   4]
 [  3  40  32 531  18   0  22   0  64]
 [ 28  16   9   6 267  29  22  59  11]
 [  6   0   0   0  18 212   0   0   0]
 [  1   0   8   0   0   0 137   3   0]
 [ 11   2  26   0  18   4  54 405   9]
 [  2  72  45  11   2   0  13   1 357]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.673901098901
[[171   0   3   1  21   5   1   0   1]
 [  4 224   9  16   0   0   5   0  31]
 [  2   0 153   0   1   0  32   3   6]
 [ 20  97  80 587  23   0  92   2 164]
 [116  48  25  14 341 126  45   8  35]
 [  0   0   0   0   7 151   0   0   0]
 [  1   0   6   0   0   0 129  13   0]
 [  5   2  26   0  10   4  50 444   7]
 [  0   9   8   1   0   0   2   0 253]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.613906840564

0.679945054945
[[212  12  10   4  57  20  11   0  10]
 [ 12 231  20  64   4   3   8   0  92]
 [  4   9 162   3  14   1  48   6  24]
 [  3  48   8 491   1   0  11   1  46]
 [ 44   9   9   1 256  47  10   7   4]
 [ 22   2   0   1  53 213   0   0   0]
 [ 15   5  47   7  11   1 195  47  12]
 [  0   1   7   1   1   1  48 408   2]
 [  7  63  47  47   6   0  25   1 307]]

### RandomForestClassifier ###
score.mean():  0.697798614786

0.756043956044
[[249   5  11   5  62  18   9   0   8]
 [  4 295   6  68   1   0   7   0  81]
 [  5   2 200   2   6   1  61   6  40]
 [  1  37   5 521   4   0   6   0  45]
 [ 38   1   4   0 291  37   8   4   3]
 [ 11   0   1   0  33 229   0   0   0]
 [  6   4  43   0   3   0 227  31   9]
 [  0   0   1   0   1   1  32 429   0]
 [  5  36  39  23   2   0   6   0 311]]

### ExtraTreesClassifier ###
score.mean():  0.69267643069

0.766208791209
[[244   7   9   5  56  16   7   0   4]
 [  6 297  18  41   1   0   8   0  65]
 [ 10   7 194   0   7   1  56   8  36]
 [  3  32   3 541   2   0   4   0  50]
 [ 38   2   8   0 288  43   9   4   3]
 [ 12   0   2   0  37 226   1   0   0]
 [  3   2  47   0   7   0 233  26   5]
 [  0   0   3   0   0   0  29 432   0]
 [  3  33  26  32   5   0   9   0 334]]

###  BaggingClassifier ###
score.mean():  0.782780402387

0.813736263736
[[260   6   3   8  62  19   3   0   3]
 [  5 312   7  39   1   0  18   0  46]
 [ 11   6 243   9   8   0  57   8  24]
 [  0  14   0 534   2   0   0   0  22]
 [ 22   3   0   0 286  11   2   3   2]
 [ 18   0   0   0  41 256   0   0   0]
 [  2   0  47   4   2   0 257  35  10]
 [  0   0   0   0   0   0  17 424   0]
 [  1  39  10  25   1   0   2   0 390]]
######################################################
(5460, 74) (3640, 74)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.795604395604
[[  0  58  82  49  59  71  31  64   1  83]
 [  0 257   5   4   2  30   7   0   0   6]
 [  0   2 293   0  11   0   0   1   0  20]
 [  0   4   0 205   0   2   0  35   0   6]
 [  0   0   7   0 564   0   0   1   0   3]
 [  0   6   2   0   0 285  11   1   0   0]
 [  0   6   0   0   0  10 252   0   0   0]
 [  0   0   0  14   0   0   0 196  11   3]
 [  0   0   0   2   0   0   0  18 469   0]
 [  0   0   6   1   7   0   0   2   0 375]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.853846153846
[[283  16   8  20  32  23   3   0   8]
 [  2 314   8  33   0   0  10   0  23]
 [  4   0 229   5   2   1  76   1   9]
 [  0   7   0 565   0   0   2   0   3]
 [ 38   6   5   0 353  25   6   0   3]
 [  6   0   0   0  10 252   0   0   0]
 [  0   0  14   0   0   0 196  11   3]
 [  0   0   2   0   0   0  18 469   0]
 [  0  52   9  20   1   0   7   0 447]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.702197802198
[[258  20   5  40  43  48  17   1   5]
 [  6 228  25  26  12   0  18   0  41]
 [  3   3 118   1  11   1  49   2   3]
 [  2  46  19 556  16   0  20   0  55]
 [ 31  17   8   6 267  41  16  50   4]
 [  7   0   0   0   9 207   0   0   0]
 [  0   0   9   0   0   0 134   7   0]
 [ 24   3  52   0  37   4  54 419  19]
 [  2  78  39  14   3   0  10   2 369]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.692582417582
[[204   3   2   3  12   9   0   0   1]
 [  3 229   4  12   0   0   1   0  29]
 [  3   0 158   0   3   0  23   1   7]
 [ 24 108  70 615  24   0 122  36 144]
 [ 94  41  21  10 346 123  41  21  33]
 [  2   0   0   0   7 165   0   0   0]
 [  0   0   3   0   0   0 105   5   0]
 [  3   1  15   0   5   4  24 418   1]
 [  0  13   2   3   1   0   2   0 281]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.618330293956

0.666208791209
[[197  20   8   7  63  30   5   0   8]
 [ 22 232  13  51   3   2  20   0  94]
 [ 11  11 165   7  16   0  47  11  52]
 [  3  39   4 512   2   0   6   0  39]
 [ 47   8  10   1 245  49   9   0   6]
 [ 35   1   2   1  46 219   3   1   0]
 [ 12   8  39   7  10   1 171  59  17]
 [  0   0  11   0   3   0  42 407   3]
 [  6  76  23  57  10   0  15   3 277]]

### RandomForestClassifier ###
score.mean():  0.704581973298

0.776648351648
[[267   8  10   5  60  25  13   0   6]
 [  8 302   8  50   0   0   6   0  69]
 [  9   7 193   0   8   0  59   3  31]
 [  1  36   3 553   3   0   6   0  30]
 [ 32   3   7   1 292  32   9   3   5]
 [  9   1   2   0  28 243   0   0   0]
 [  2   1  35   1   3   0 199  43   9]
 [  0   0   2   0   0   0  19 432   0]
 [  5  37  15  33   4   1   7   0 346]]

### ExtraTreesClassifier ###
score.mean():  0.699455868889

0.770879120879
[[262   9  11   7  62  20   6   0  12]
 [  8 294   9  48   2   0   8   0  91]
 [  7   6 194   0  10   1  58   5  36]
 [  0  30   1 565   3   0   5   0  33]
 [ 35   7   5   0 294  35   8   2   3]
 [ 17   1   0   0  25 245   0   0   0]
 [  2   1  39   1   1   0 204  44   3]
 [  0   0   2   0   0   0  19 430   0]
 [  2  47  14  22   1   0  10   0 318]]

###  BaggingClassifier ###
score.mean():  0.7820467504

0.816483516484
[[283  14   6  18  52  25   4   1   6]
 [  3 310   6  29   2   0  14   0  63]
 [  8   5 226   8  10   0  65   3  18]
 [  0  18   1 569   0   0   2   0  12]
 [ 19   5   1   0 299  17   4   0   1]
 [ 19   0   1   0  32 259   1   0   0]
 [  1   0  29   1   1   0 211  50   8]
 [  0   0   0   0   0   0  14 427   0]
 [  0  43   5  18   2   0   3   0 388]]
######################################################
(5460, 74) (3640, 74)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.789835164835
[[  0  52  79  51  46  79  25  62   3  92]
 [  0 245   5   0   0  26   8   0   0   6]
 [  0   3 294   0   5   1   0   1   0  17]
 [  0   4   0 205   0   3   0  31   1   9]
 [  0   0   7   0 570   1   0   2   0   8]
 [  0  11   0   0   0 266  12   3   0   0]
 [  0   3   0   0   0  21 245   0   0   0]
 [  0   1   0  20   1   0   0 213  12   2]
 [  0   0   0   2   0   0   0  25 479   0]
 [  0   0  12   2  11   0   0   0   0 358]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.850549450549
[[265  13   5   6  31  21   3   0  11]
 [  3 315   9  24   2   0  17   0  24]
 [  5   0 231   2   3   0  61   4  11]
 [  0   7   0 573   1   0   3   0   8]
 [ 40   3   1   0 339  24   8   0   0]
 [  3   0   0   0  21 245   0   0   0]
 [  1   0  20   1   0   0 213  12   2]
 [  0   0   2   0   0   0  25 479   0]
 [  2  59  12  27   0   0   7   0 436]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.707692307692
[[253  21   4  37  48  47  24   0   5]
 [ 15 243  29  17   4   1  17   0  44]
 [  4   0 113   0  15   0  46   4   5]
 [  5  38  23 564  15   0  20   0  70]
 [ 23  10   9   4 267  22  18  47   9]
 [  3   0   0   0  19 213   0   0   1]
 [  0   0   8   1   0   0 149  12   0]
 [ 13   0  44   0  28   7  52 431  15]
 [  3  85  50  10   1   0  11   1 343]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.692032967033
[[214   2   0   2  18  19   1   0   3]
 [  7 231   7   7   0   0   4   0  23]
 [  4   1 133   0   4   0  22   2   6]
 [ 20 104  90 616  31   1 103  26 151]
 [ 67  42  22   3 331  95  48  21  41]
 [  1   0   0   0   8 171   0   0   0]
 [  0   0   5   0   0   0 125  12   0]
 [  6   0  20   0   5   4  34 434   4]
 [  0  17   3   5   0   0   0   0 264]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.596710576792

0.678571428571
[[205  10   9   7  54  33  12   0   9]
 [ 12 234  16  44   7   4  11   2  80]
 [  6  13 119   6   8   1  45   3  39]
 [  6  49   2 533   6   0   7   0  56]
 [ 47  11  15   4 270  38  14   3   8]
 [ 24   2   4   0  36 214   2   0   1]
 [ 10   8  49   5   9   0 184  56  14]
 [  0   0   6   0   1   0  44 429   3]
 [  9  70  60  34   6   0  18   2 282]]

### RandomForestClassifier ###
score.mean():  0.700187559388

0.771428571429
[[254   8   8   3  58  23   8   0   5]
 [  7 301  12  36   6   0   8   0  69]
 [  6   5 201   2   8   0  57   8  29]
 [  2  38   1 567   1   0   6   0  52]
 [ 38   4   4   0 289  32   9   1   6]
 [ 10   1   0   0  29 235   1   0   1]
 [  1   0  33   1   1   0 201  48   8]
 [  0   0   0   0   0   0  38 438   0]
 [  1  40  21  24   5   0   9   0 322]]

### ExtraTreesClassifier ###
score.mean():  0.691203638872

0.766483516484
[[247   8  11   2  58  28  13   0  11]
 [  9 298   9  35   6   0   5   0  67]
 [  6   5 198   1   4   1  59   6  31]
 [  2  41   5 571   3   0   3   0  55]
 [ 40   1   7   0 281  39  12   0   3]
 [  7   2   0   0  33 222   0   0   0]
 [  3   0  31   1   7   0 211  44   8]
 [  0   0   0   0   0   0  29 445   0]
 [  5  42  19  23   5   0   5   0 317]]

###  BaggingClassifier ###
score.mean():  0.785344367503

0.811813186813
[[267   9   2   6  54  22   2   0   8]
 [  5 311   8  18   3   0  16   0  51]
 [  7   4 226   4  10   0  58   9  26]
 [  0  20   0 578   1   0   4   0  27]
 [ 22   3   1   0 285  20   6   0   0]
 [ 16   0   0   0  43 248   0   0   0]
 [  1   1  36   4   0   0 224  47   3]
 [  0   0   0   0   0   0  23 439   0]
 [  1  49   7  23   1   0   4   0 377]]
######################################################
(5460, 74) (3640, 74)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.78489010989
[[  0  60  81  41  67  78  23  66   4  80]
 [  0 229   3   1   2  32  11   0   0   5]
 [  0   5 315   1  14   0   0   5   0  27]
 [  0   4   0 230   0   0   0  23   1   4]
 [  0   0  11   0 542   0   0   0   0   5]
 [  0  11   1   0   0 269   6   2   1   0]
 [  0   5   0   0   0  19 230   0   0   0]
 [  0   1   0  16   1   0   0 214  12   7]
 [  0   0   0   1   0   0   0  23 468   0]
 [  0   1  12   2   6   1   0   1   0 360]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.842857142857
[[259  11   4  12  37  21   6   0  12]
 [  6 333   5  44   1   0  18   0  30]
 [  5   0 253   6   0   0  60   5   7]
 [  0  11   0 547   0   0   0   0   5]
 [ 38   6   3   0 340  19   9   2   2]
 [  5   0   0   0  19 230   0   0   0]
 [  1   0  16   1   0   0 214  12   7]
 [  0   0   1   0   0   0  23 467   0]
 [  2  62  10  22   2   0   4   0 425]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.685714285714
[[237  21   4  42  38  43  27   0   4]
 [  8 242  29  25   5   0  19   0  33]
 [  5   1 130   0  10   0  54   4   3]
 [  6  43  19 549  17   0  17   0  71]
 [ 28  16   4   5 260  34  18  58   8]
 [  6   0   0   0  20 188   0   0   0]
 [  1   0   8   1   0   0 141  11   1]
 [ 20   4  55   1  44   5  48 412  31]
 [  5  96  43   9   5   0  10   1 337]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.681043956044
[[227   6   1   8  33  21   8   0   5]
 [  4 247   3  12   0   0   5   0  24]
 [  3   0 160   0   3   0  28   2   5]
 [ 28 113  71 589  28   1  92  15 163]
 [ 48  44  18  19 320  88  39  49  31]
 [  2   0   0   0   8 157   0   0   0]
 [  0   0   6   0   0   0 122  14   0]
 [  3   0  31   1   7   3  39 406   9]
 [  1  13   2   3   0   0   1   0 251]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.615009776981

0.671978021978
[[207  17   8   7  59  26  11   2  11]
 [ 13 252  16  54   2   2  10   0  62]
 [  8   8 143   6   9   1  49   6  46]
 [  6  58   4 500   4   0   4   0  57]
 [ 49   8   8   0 260  42  13   4   9]
 [ 25   2   0   0  43 197   1   0   2]
 [  4   3  68  12  12   1 185  51  17]
 [  0   0   8   0   1   0  50 421   3]
 [  4  75  37  53   9   1  11   2 281]]

### RandomForestClassifier ###
score.mean():  0.703122685324

0.757967032967
[[246   7  10   6  61  15   6   0  11]
 [  9 316  12  46   0   0   8   0  78]
 [  7   4 203   1  13   2  71   9  39]
 [  2  43   3 545   1   0   5   0  35]
 [ 23   6   4   0 287  38   8   3   4]
 [ 18   1   0   0  31 215   0   0   0]
 [  8   1  34   0   2   0 211  49  10]
 [  0   0   3   0   0   0  22 425   0]
 [  3  45  23  34   4   0   3   0 311]]

### ExtraTreesClassifier ###
score.mean():  0.69890961836

0.765384615385
[[242   9  16  11  63  23  12   0  12]
 [ 14 325   6  48   2   0   6   0  80]
 [  7   3 209   2   6   1  60   7  30]
 [  2  45   2 544   3   0   2   0  39]
 [ 29   9   2   0 289  32  10   3   6]
 [ 16   0   1   0  30 214   0   0   2]
 [  0   1  36   0   2   0 208  32   8]
 [  0   0   3   0   0   0  30 444   0]
 [  6  31  17  27   4   0   6   0 311]]

###  BaggingClassifier ###
score.mean():  0.786630261228

0.806868131868
[[251   9   4  12  59  20   2   0  11]
 [  6 334   4  38   2   0  19   0  52]
 [  9   6 246   9   8   0  54   7  19]
 [  0  20   0 546   0   0   0   0  19]
 [ 25   5   0   0 285  14   7   2   0]
 [ 21   1   0   0  39 236   0   0   0]
 [  2   0  33   6   2   0 235  49  11]
 [  0   0   0   0   0   0  16 428   0]
 [  2  48   5  21   4   0   1   0 376]]
######################################################
(5460, 74) (3640, 74)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.790659340659
[[  0  62  73  55  55  75  21  59   1  87]
 [  0 243   6   2   4  24   9   0   0   2]
 [  0   4 340   0  12   2   0   0   0  17]
 [  0   2   1 200   0   2   0  30   2  10]
 [  0   0   7   0 532   1   0   0   0   5]
 [  0   9   0   0   0 279  14   2   0   0]
 [  0  11   0   0   0  13 242   0   0   0]
 [  0   2   0  17   1   0   0 207   2   4]
 [  0   0   0   1   0   0   0  32 484   0]
 [  0   1  13   2   8   0   0   0   0 351]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.848901098901
[[266  12   7  14  29  19   7   0   6]
 [  6 360  10  32   4   0   9   0  23]
 [  3   1 230   6   2   0  62   3  14]
 [  0   7   0 534   1   0   0   0   5]
 [ 44   3   2   0 345  25   6   0   2]
 [ 11   0   0   0  13 242   0   0   0]
 [  2   0  17   1   0   0 207   2   4]
 [  0   0   1   0   0   0  32 484   0]
 [  2  57  10  25   2   0   7   0 422]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.70467032967
[[261  18   6  42  37  49  19   0   3]
 [ 14 266  26  20   8   0  15   0  17]
 [  2   1 113   1  17   1  54   3   5]
 [  5  41  22 535  11   0  15   0  67]
 [ 24  16   6   4 287  36  19  64  10]
 [  7   0   0   0  15 197   0   0   0]
 [  2   0   9   0   0   0 128   2   1]
 [ 16   5  52   0  18   3  71 420  15]
 [  3  93  43  10   3   0   9   0 358]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.683241758242
[[210   8   1   6  17  14   5   0   1]
 [  5 259   0  10   1   0   1   0  11]
 [  3   1 136   0   1   0  28   2  10]
 [ 39  90  81 578  31   1 102  15 151]
 [ 66  64  26  13 335 112  38  28  42]
 [  5   0   0   0   8 158   0   0   0]
 [  0   0   6   0   0   0 113   6   0]
 [  6   0  23   0   3   1  43 438   1]
 [  0  18   4   5   0   0   0   0 260]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.619223212756

0.665659340659
[[193  19  13   7  56  20  12   2   8]
 [  6 264  12  40   5   1   8   0  70]
 [ 11  17 130   7  10   1  57  13  35]
 [  6  55   6 488   3   1   4   0  53]
 [ 68   6  11   2 255  55   5   2   5]
 [ 20   2   3   0  36 205   2   0   1]
 [ 15  15  60   8  15   2 183  53  15]
 [  0   0   4   0   1   1  46 419   3]
 [ 15  62  38  60  15   0  13   0 286]]

### RandomForestClassifier ###
score.mean():  0.70017768376

0.762087912088
[[257  15  13  13  50  22   7   0   6]
 [  9 295   8  31   4   0   5   0  49]
 [ 11   5 181   0   9   0  62   4  29]
 [  1  45   1 540   3   0   4   0  56]
 [ 40   3   4   1 305  38   7   2   4]
 [  7   2   0   0  19 225   0   0   0]
 [  6   4  48   1   2   0 204  36  12]
 [  0   0   1   0   0   1  34 447   0]
 [  3  71  21  26   4   0   7   0 320]]

### ExtraTreesClassifier ###
score.mean():  0.708062207149

0.768681318681
[[255  14   9   8  59  25   8   0   7]
 [  7 309   5  47   6   0   6   0  54]
 [  8   3 195   0   9   1  56   6  23]
 [  0  42   0 535   1   0   5   0  41]
 [ 43   7   9   0 292  32   8   2   5]
 [ 11   1   0   0  25 228   0   0   0]
 [  3   1  29   0   2   0 202  36   9]
 [  0   0   0   0   0   0  39 445   0]
 [  7  63  30  22   2   0   6   0 337]]

###  BaggingClassifier ###
score.mean():  0.786073174251

0.816483516484
[[268  11   5  13  56  17   2   1   5]
 [  6 360   8  29   5   0   9   0  53]
 [ 10   8 216   8   7   0  59   7  29]
 [  0  19   1 540   1   0   1   0  12]
 [ 28   4   0   0 294  23   4   0   0]
 [ 21   0   0   0  31 246   0   0   0]
 [  1   0  38   3   1   0 233  31  12]
 [  0   0   0   0   0   0  21 450   0]
 [  0  38   9  19   1   0   1   0 365]]
######################################################
(5460, 74) (3640, 74)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.796428571429
[[  0  41  70  58  58  79  24  49   1  90]
 [  0 261   6   3   2  34  12   1   0   5]
 [  0   2 289   1   9   0   0   1   0  19]
 [  0   2   0 210   0   1   0  33   1   2]
 [  0   0   7   0 536   2   0   0   0  11]
 [  0  12   0   0   0 278  16   2   0   0]
 [  0   5   0   0   0  17 238   0   0   0]
 [  0   3   0  12   0   0   0 212   5   3]
 [  0   0   0   1   0   0   0  19 512   0]
 [  0   0   9   4   6   2   0   1   0 363]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.853296703297
[[279  13   6   8  39  25   3   0   8]
 [  3 301  10  35   1   0   9   0  27]
 [  2   0 241   5   1   1  64   2   6]
 [  0   7   0 540   2   0   0   0  11]
 [ 34   2   5   0 349  26   5   3   1]
 [  5   0   0   0  17 238   0   0   0]
 [  3   0  12   0   0   0 212   5   3]
 [  0   0   1   0   0   0  19 509   0]
 [  0  58  14  23   4   0   6   0 437]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.705494505495
[[267   9  10  39  69  42  27   1   5]
 [ 16 236  51  30  11   3  25   0  45]
 [  3   0 139   0  16   1  66   2   4]
 [  3  38  23 527  14   0  14   0  78]
 [ 27  17   5   7 282  38  17  72  13]
 [  5   0   0   0  16 205   0   0   0]
 [  3   0   6   0   0   0 123   2   0]
 [  0   0   8   0   1   1  36 441   0]
 [  2  81  47   8   4   0  10   1 348]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.701923076923
[[191   0   2   0  21  10   2   0   2]
 [ 10 242  26   9   4   1   9   1  29]
 [  1   0 134   0   4   1  26   1   3]
 [ 24  85  75 593  25   0  83   9 159]
 [ 96  41  30   7 351 107  40  20  31]
 [  4   0   0   0   7 171   0   0   0]
 [  0   0   5   0   0   0 121   5   0]
 [  0   0   7   0   0   0  37 483   0]
 [  0  13  10   2   1   0   0   0 269]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.617050374199

0.682692307692
[[194   4   8   4  63  30  10   2  10]
 [ 17 229  18  49   9   2   9   0  51]
 [  7   7 140   5  10   0  56  16  37]
 [  3  45   6 495   3   1   6   0  54]
 [ 62   4   8   3 274  45   5  11   7]
 [ 18   5   2   0  39 211   0   0   0]
 [ 12   9  68   3   9   0 180  42  19]
 [  5   0   1   1   1   1  41 448   1]
 [  8  78  38  51   5   0  11   0 314]]

### RandomForestClassifier ###
score.mean():  0.706789025277

0.764010989011
[[237   8   9   5  63  26   2   0   9]
 [  6 287   9  42   3   0   8   0  65]
 [  5   4 193   2   6   0  57  10  33]
 [  0  34   1 529   3   0   3   0  46]
 [ 44   2  12   0 308  43   9   4   5]
 [ 22   2   0   0  25 221   0   0   0]
 [  7   2  32   0   3   0 207  35   6]
 [  0   0   1   0   0   0  27 470   0]
 [  5  42  32  33   2   0   5   0 329]]

### ExtraTreesClassifier ###
score.mean():  0.708066244221

0.763186813187
[[244   5  12   2  69  33   8   0   5]
 [  9 295  17  46   1   0   3   0  77]
 [  9   3 172   1   6   0  48   6  31]
 [  0  31   3 539   3   0   3   0  51]
 [ 38   1   8   0 287  28   6   2   5]
 [ 17   2   1   0  37 227   0   0   1]
 [  6   1  44   0   6   1 218  30   8]
 [  0   0   2   0   0   1  22 481   0]
 [  3  43  30  23   4   0  10   0 315]]

###  BaggingClassifier ###
score.mean():  0.783695626767

0.813186813187
[[277  11   5   8  68  26   2   0   9]
 [  4 305   9  32   0   0  12   0  50]
 [  6   7 231   5  10   1  63   6  14]
 [  0  14   0 543   2   0   1   0  26]
 [ 20   2   0   0 289  22   3   3   0]
 [ 16   0   0   0  41 241   0   0   0]
 [  3   0  33   4   1   0 222  41  11]
 [  0   0   0   0   0   0  14 469   0]
 [  0  42  11  19   2   0   1   0 383]]
######################################################
(5460, 74) (3640, 74)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.793406593407
[[  0  53  69  60  54  68  18  64   1  89]
 [  0 242   1   4   2  33  12   2   0   1]
 [  0   4 318   0  15   1   0   1   0  19]
 [  0   2   0 217   1   0   0  35   2   5]
 [  0   0   6   0 552   2   0   0   0   5]
 [  0  13   2   0   0 294  15   1   0   0]
 [  0   6   0   0   0  17 231   0   0   0]
 [  0   0   0  18   0   0   0 217   8   4]
 [  0   0   0   2   0   0   0  18 456   0]
 [  0   0  10   2   6   0   0   1   0 361]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.851923076923
[[265  10   9  13  38  19   8   0   8]
 [  4 333   4  36   1   0  11   0  26]
 [  2   0 255   4   0   0  70   3   6]
 [  0   6   0 557   2   0   0   0   6]
 [ 42   7   2   0 357  26   9   2   2]
 [  6   0   0   0  17 231   0   0   0]
 [  0   0  18   0   0   0 217   8   4]
 [  0   0   2   0   0   0  18 454   0]
 [  1  50  13  20   0   0   6   0 432]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.688186813187
[[250  15  14  50  48  39  24   0   2]
 [ 11 256  17  30   5   0  14   0  37]
 [  3   0 118   0  10   0  56   3   4]
 [  7  44  36 536  13   0  26   0  66]
 [ 23  19   9   4 290  35  18  69  13]
 [  6   0   0   0  18 196   0   0   0]
 [  0   0  10   0   0   0 130   4   0]
 [ 20   1  43   0  29   6  61 387  20]
 [  0  71  56  10   2   0  10   4 342]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.640934065934
[[154   1   3   2  15   4   3   0   0]
 [  4 215   4  16   1   0   6   0  30]
 [  2   0 161   0   1   0  40   3   7]
 [ 11  85  35 571  13   0  38   0 131]
 [131  85  28  38 365 216  40  24  45]
 [  0   0   0   0   2  51   0   0   0]
 [  1   0  12   0   0   0 141  16   0]
 [ 17   2  40   0  18   5  70 423  19]
 [  0  18  20   3   0   0   1   1 252]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.612631556102

0.670604395604
[[203  11  16  10  53  19  11   0  15]
 [  8 238   6  68   5   4  10   0  69]
 [ 15  13 150   4  15   2  57   8  40]
 [  2  62   6 487   4   0   8   0  57]
 [ 53  10  13   8 277  36  10   4   6]
 [ 20   5   0   0  40 212   0   0   0]
 [ 15   5  62   5   8   1 184  46  14]
 [  0   0   7   0   6   1  50 408   1]
 [  4  62  43  48   7   1   9   1 282]]

### RandomForestClassifier ###
score.mean():  0.696139732814

0.757142857143
[[246   7  10   5  62  14   9   0   7]
 [  9 302  10  53   1   0   7   0  72]
 [  7   5 202   1  11   3  70   9  36]
 [  1  41   2 548   1   0   3   1  45]
 [ 33   6   3   0 299  35   7   3   3]
 [ 15   1   1   0  36 223   0   0   0]
 [  5   1  45   0   3   1 206  30  15]
 [  0   0   4   0   0   0  29 424   0]
 [  4  43  26  23   2   0   8   0 306]]

### ExtraTreesClassifier ###
score.mean():  0.709885981535

0.757967032967
[[241   8  10   5  67  20  10   1  15]
 [ 10 294   4  57   2   1   7   0  77]
 [  9   7 217   2  13   2  55   5  30]
 [  0  51   1 543   4   0   2   0  35]
 [ 35   5   6   0 288  36   5   3   1]
 [ 19   0   0   0  33 217   1   0   1]
 [  4   0  40   0   4   0 228  39  13]
 [  0   0   4   0   1   0  19 419   0]
 [  2  41  21  23   3   0  12   0 312]]

###  BaggingClassifier ###
score.mean():  0.78350282186

0.817307692308
[[266   9   5  12  62  20   5   0   7]
 [  6 334   5  30   1   0   9   0  51]
 [  4   6 242   7   4   1  65  10  19]
 [  0  12   0 559   2   0   0   0  23]
 [ 26   6   0   0 309  21   6   2   0]
 [ 17   0   2   0  36 234   0   0   0]
 [  0   0  42   4   0   0 239  35  12]
 [  0   0   0   0   0   0  14 420   0]
 [  1  39   7  18   1   0   1   0 372]]
######################################################
######################################################
comb 0 :
[ 0.79203297  0.78901099  0.79505495  0.79148352  0.7956044   0.78983516
  0.78489011  0.79065934  0.79642857  0.79340659]
0.791840659341
comb 1 :
[ 0.8532967   0.85631868  0.85934066  0.85769231  0.85384615  0.85054945
  0.84285714  0.8489011   0.8532967   0.85192308]
0.852802197802
comb 2 :
[ 0.68791209  0.69862637  0.71648352  0.7         0.7021978   0.70769231
  0.68571429  0.70467033  0.70549451  0.68818681]
0.699697802198
comb 3 :
[ 0.59862637  0.58543956  0.67335165  0.6739011   0.69258242  0.69203297
  0.68104396  0.68324176  0.70192308  0.64093407]
0.662307692308
comb 4 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 5 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 6 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 7 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 8 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 9 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 0 :
[ 0.66620879  0.67252747  0.66785714  0.67994505  0.66620879  0.67857143
  0.67197802  0.66565934  0.68269231  0.6706044 ]
0.672225274725
ens 1 :
[ 0.76648352  0.77087912  0.76208791  0.75604396  0.77664835  0.77142857
  0.75796703  0.76208791  0.76401099  0.75714286]
0.764478021978
ens 2 :
[ 0.76675824  0.77005495  0.76565934  0.76620879  0.77087912  0.76648352
  0.76538462  0.76868132  0.76318681  0.75796703]
0.766126373626
ens 3 :
[ 0.81730769  0.81868132  0.81840659  0.81373626  0.81648352  0.81181319
  0.80686813  0.81648352  0.81318681  0.81730769]
0.815027472527
ens 4 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 5 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 6 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 7 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 8 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 9 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
