Starting read from Train file...
(9100, 65)
train.shape = (9100, 64)
train_labels.shape = (9100, 1)
(5460, 64) (3640, 64)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.557417582418
[[  0 132  89  93 103  94  68 102   7 118]
 [  0  85  16   0   0  25  16   3   0   3]
 [  0  40 225  36   1   3   1  16   9  27]
 [  0   1  10  64   0   2   0  13   0  16]
 [  0   9   2   3 454  15   0  11   0  76]
 [  0  36   3   0   5 265  11   1   3   2]
 [  0  14   3   0   0  15 167   0   0   0]
 [  0   6  10  27  15   0   0 134  14  25]
 [  0  10  45   2   0   0   2  26 454   5]
 [  0  13  18  52  50   3   0  35   0 181]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.63489010989
[[149  41   4   3  43  61  11   2   6]
 [ 47 257  60   3   3   6  27  12  38]
 [  4  12  82   4   2   0  30   1  27]
 [  9   2   3 463  15   0  20   0  78]
 [ 64  13   3  14 338  29  12   4   7]
 [ 14   3   0   0  15 167   0   0   0]
 [  6  10  27  15   0   0 134  14  25]
 [ 10  45   2   0   0   2  26 454   5]
 [ 43  38  96 126   6   0  81   0 267]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.496428571429
[[ 50   6   3   4  41  48  10   1   3]
 [ 36 104  28   1   6  14  19   7  18]
 [  0   0   2   0   0   0   0   0   1]
 [ 44  10  23 554  67   7  44   0 171]
 [ 30   4   0   2 225  19   3   3   1]
 [ 17   8   2   0  29 122   1   1   0]
 [  4   6  18   9   0   0  77  10  16]
 [ 74 166  77   0  21  25  66 464  34]
 [ 91 117 124  58  33  30 121   1 209]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.535164835165
[[ 43   7   0   0  14  11   5   0   2]
 [ 39 160  35   1   3  12  15   7  21]
 [  0   4  24   0   0   0   6   0   7]
 [ 44  15  27 551  38   7  42   0 176]
 [ 89  20  14  16 345 120  32  11  15]
 [ 10   6   1   0   9  85   0   0   0]
 [  3   9  17  10   0   0  85   7  12]
 [ 69 139  56   0   9  21  59 462  27]
 [ 49  61 103  50   4   9  97   0 193]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.456258129931

0.459615384615
[[ 71  48  32  39  51  39  29  25  36]
 [ 58 161  51   5  10  15  39  38  33]
 [ 40  50  63  20   3   8  44   8  50]
 [ 33   8  13 391  29   3  36   0 102]
 [ 35   9   5  26 231  49   9   4  11]
 [ 30  27   8   5  68 126   5  21   6]
 [ 24  35  42  18   9   3  99  24  42]
 [ 21  43   2   0   0   7  23 364   6]
 [ 34  40  61 124  21  15  57   3 167]]

### RandomForestClassifier ###
score.mean():  0.538098935003

0.571428571429
[[100  47  23  16  28  42  24  10  33]
 [ 69 235  66   4  11  18  35  38  34]
 [ 23  37  86   4   4   7  46   0  37]
 [ 29   1  14 517  35   2  28   1 109]
 [ 45   9   3  14 289  50   8   2   5]
 [ 21  15   6   0  41 131   5   7   3]
 [ 18  18  30  12   1   8 122  13  45]
 [  9  38   2   0   1   3  18 416   3]
 [ 32  21  47  61  12   4  55   0 184]]

### ExtraTreesClassifier ###
score.mean():  0.54103688983

0.569230769231
[[105  42  26  11  42  38  21  11  35]
 [ 80 238  59   3  13  20  39  30  34]
 [ 12  29  87   6   3   4  40   0  44]
 [ 32   4  15 504  39   5  27   1 115]
 [ 40   7   0  15 270  51   5   2   6]
 [ 18  22   6   0  45 137   7   3   3]
 [ 19  21  27  18   1   4 131  12  39]
 [ 12  36   1   0   2   2  20 428   5]
 [ 28  22  56  71   7   4  51   0 172]]

###  BaggingClassifier ###
score.mean():  0.618344230804

0.624725274725
[[135  35   4   0  49  43   3   0   3]
 [ 55 267  55   1  10   4  28  25  34]
 [  6  27  78   1   6   0  34   3  31]
 [ 14   5   7 465  37   0  13   0  91]
 [ 55   3   1  12 286  21   9   4   6]
 [ 28   3   0   0  25 197   0   0   0]
 [ 11  17  46  30   1   0 173  32  33]
 [  0  30   2   0   0   0  14 423   5]
 [ 42  34  84 119   8   0  67   0 250]]
######################################################
(5460, 64) (3640, 64)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.55989010989
[[  0 133  77 116 107 115  59  81   6 139]
 [  0  96   7   0   0  16   7   2   0   0]
 [  0  48 224  39   0   4   0  14   9  27]
 [  0   1  13  58   2   4   0  11   0   7]
 [  0   9   1   3 437   6   0   7   0  77]
 [  0  28   1   0   5 242  12   0   1   2]
 [  0   8   1   0   0  15 201   0   0   0]
 [  0   4   8  39  20   0   0 149  17  23]
 [  0   4  52   7   0   5   2  12 451   3]
 [  0  19  19  53  55   3   0  37   0 180]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.64532967033
[[161  36   9   2  42  45   8   1   7]
 [ 53 251  69   3   5   2  25  11  37]
 [  2  13  75   2   5   0  23   2  15]
 [  9   1   5 449   7   0  14   0  79]
 [ 60   7   3  15 325  31   7   3   6]
 [  8   1   0   0  15 201   0   0   0]
 [  4   8  39  20   0   0 149  17  23]
 [  4  52   7   0   0   2  12 450   3]
 [ 49  34 108 135  11   0  75   0 288]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.491208791209
[[ 45   5   3   2  36  41   9   2   0]
 [ 33 108  30   1   8   7  23   4  26]
 [  0   0   1   0   0   0   2   0   3]
 [ 48  10  24 542  67   7  35   0 185]
 [ 28   0   0   5 193  14   1   2   2]
 [ 15   3   2   0  33 145   1   0   0]
 [  3   6  32   8   2   0  95  11  21]
 [ 86 155  86   3  33  33  53 462  24]
 [ 92 116 137  65  38  34  94   3 197]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.500274725275
[[ 30   2   0   0   8   7   2   0   0]
 [ 28 122  27   0   8   6  11   5  23]
 [  1   6  22   0   1   0   8   0   6]
 [ 64  21  33 564  92   9  38   1 194]
 [ 62  10   7   9 272 121  13   7   5]
 [ 10   2   1   0   9  83   0   0   0]
 [  2   8  25   8   0   2  76   6  15]
 [ 96 181  90   5  16  50  75 465  28]
 [ 57  51 110  40   4   3  90   0 187]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.437359999244

0.469230769231
[[ 68  55  32  25  32  31  32  23  30]
 [ 57 157  61  10  17  27  29  48  38]
 [ 32  45  74  14   8   9  39   8  50]
 [ 36   4  25 409  40   5  22   0 109]
 [ 47  12   5  21 223  50   6   6   6]
 [ 31  20   5   3  66 140   5   8   5]
 [ 32  33  49  29   4   4 108  23  46]
 [ 13  40   9   1   2  11  22 360   5]
 [ 34  37  55 114  18   4  50   8 169]]

### RandomForestClassifier ###
score.mean():  0.546534779143

0.559065934066
[[ 81  58  23  16  38  25  23  12  23]
 [ 78 222  62   5  12  21  36  29  41]
 [ 13  26  93   3   4   5  25   2  33]
 [ 37   3  11 475  24   1  23   0 119]
 [ 45   7   3  16 262  55   3   2   7]
 [ 28  11   7   2  57 162   4   3   2]
 [ 23  20  53  16   2   3 131  15  39]
 [  8  37   4   0   1   4  18 420   5]
 [ 37  19  59  93  10   5  50   1 189]]

### ExtraTreesClassifier ###
score.mean():  0.545075213095

0.555769230769
[[ 82  57  36  18  28  33  17   9  21]
 [ 90 218  60   7  14  23  41  29  40]
 [ 28  28  89  10   4   4  26   3  38]
 [ 31   4  18 472  40   2  24   0 123]
 [ 43   4   2  16 268  53   4   1   8]
 [ 24  14   5   1  48 156   6   2   3]
 [ 18  18  42  19   3   3 133  19  37]
 [  7  40   5   0   0   4  13 420   3]
 [ 27  20  58  83   5   3  49   1 185]]

###  BaggingClassifier ###
score.mean():  0.612845432513

0.627197802198
[[140  22   7   0  46  26   4   0   3]
 [ 64 260  66   1  12   3  28  22  33]
 [  4  28  76   2  10   0  21   3  20]
 [ 13   6  10 460  37   0   7   0  96]
 [ 48   1   2  11 270  24   6   1   4]
 [ 28   3   0   0  23 228   0   0   1]
 [  6  15  54  35   3   0 165  35  37]
 [  0  35   4   0   0   0   8 423   3]
 [ 47  33  96 117   9   0  74   0 261]]
######################################################
(5460, 64) (3640, 64)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.556318681319
[[  0 123 109 122 112  98  49  86   9 131]
 [  0  94   9   0   1  27   9   1   0   2]
 [  0  38 211  35   0   2   1  18  11  19]
 [  0   5   5  67   2   5   0  26   0  21]
 [  0   7   1   6 460  10   0   3   0  87]
 [  0  30   2   0   3 253  10   3   2   2]
 [  0   8   4   0   0  18 180   0   0   0]
 [  0   5  11  26  15   0   0 155  14  27]
 [  0   6  51   1   1   5   3  22 421   5]
 [  0  19  26  30  38   4   0  34   0 184]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.639835164835
[[160  51   8   5  48  41   3   3   5]
 [ 42 242  61   1   6   4  25  14  29]
 [  5   7  84   8   6   0  39   2  28]
 [  7   1   8 471  10   0   9   0  88]
 [ 57   9   3  14 326  24  14   4   5]
 [  8   4   0   0  18 180   0   0   0]
 [  5  11  26  15   0   0 155  14  27]
 [  6  51   1   1   0   3  22 420   5]
 [ 45  53  96 117   8   0  81   0 291]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.488461538462
[[ 57   3   6   4  38  32   9   1   5]
 [ 33 107  29   1  10   5  18   9  16]
 [  1   1   0   0   0   1   0   0   1]
 [ 42  20  31 557  65   7  30   2 198]
 [ 24   1   0   1 208  14   5   2   2]
 [ 16  10   1   0  39 139   1   1   0]
 [  5   5  16   6   0   0  86  13  19]
 [ 77 151  84   7  26  20  75 426  39]
 [ 80 131 120  56  36  34 124   3 198]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.530494505495
[[ 36   4   1   1  12   9   2   0   1]
 [ 35 130  29   1   8   2  16   8  12]
 [  1   8  41   0   0   0  12   0  21]
 [ 37  16  30 545  41   3  31   1 175]
 [ 80  21  12  15 326 104  21   8  10]
 [ 14   7   0   0  14 109   0   0   0]
 [  6   2  15   9   0   0  86   7  15]
 [ 54 131  38   3  12  17  52 431  17]
 [ 72 110 121  58   9   8 128   2 227]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.453129801073

0.471703296703
[[ 84  65  32  39  42  42  22  15  26]
 [ 53 156  57   8  15  13  39  47  24]
 [ 29  61  67  14   4   7  41   7  47]
 [ 21   8  20 423  32   2  32   1 122]
 [ 40  13   4  25 229  47   6   2  14]
 [ 22  25   8   6  74 119   6  13   7]
 [ 31  18  36  27   8   5 114  18  57]
 [ 13  37   2   1   0   9  25 349   5]
 [ 42  46  61  89  18   8  63   5 176]]

### RandomForestClassifier ###
score.mean():  0.559732319353

0.550274725275
[[ 87  68  37  15  44  39  27   9  32]
 [ 66 217  68   0  13  12  37  29  26]
 [ 17  35  81   3   3   1  32   0  48]
 [ 24   8  22 504  37   2  23   0 156]
 [ 35   4   1  12 252  31   4   3   4]
 [ 32  17   5   1  59 155   6   3   2]
 [ 24  18  33  23   4   2 148  17  42]
 [  9  45   3   0   1   5  17 396   5]
 [ 41  17  37  74   9   5  54   0 163]]

### ExtraTreesClassifier ###
score.mean():  0.538298886484

0.560164835165
[[104  64  30  18  37  36  19  11  26]
 [ 65 224  61   0  11  17  41  21  32]
 [ 18  21  89   7   6   6  56   4  50]
 [ 30   6  21 519  42   1  37   0 129]
 [ 31   2   1  12 245  34   4   2   3]
 [ 30  19   9   0  65 148   3   6   3]
 [ 20  27  33  17   3   2 131  19  46]
 [  8  41   4   0   3   4  15 394   4]
 [ 29  25  39  59  10   4  42   0 185]]

###  BaggingClassifier ###
score.mean():  0.620909203331

0.626098901099
[[136  32   6   1  57  34   1   1   6]
 [ 54 258  56   0   8   5  21  23  25]
 [  8  25  92   2  11   0  43   3  39]
 [ 13   9  13 483  28   0   6   0 115]
 [ 49   1   2  12 279  15  10   3   4]
 [ 22   3   0   0  26 198   0   0   0]
 [ 11  22  36  35   3   0 181  28  32]
 [  1  36   1   1   0   0  14 399   4]
 [ 41  43  81  98  10   0  72   0 253]]
######################################################
(5460, 64) (3640, 64)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.56456043956
[[  0 145  86  88  98  92  67  85   7 145]
 [  0  77   8   0   1  23  15   2   0   3]
 [  0  33 210  33   0   3   1  13  10  22]
 [  0   1  12  65   0   1   0  23   0  23]
 [  0   8   3   8 454  12   0   8   0  89]
 [  0  32   3   0   2 245   6   1   2   3]
 [  0   7   2   0   0  10 199   0   0   0]
 [  0   5  15  36  21   0   0 169  12  28]
 [  0   3  39   3   0   0   2  24 461  10]
 [  0  17  25  39  43   2   0  25   0 175]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.647527472527
[[157  42   6   3  44  64   8   1  12]
 [ 40 237  53   0   5   4  23  13  33]
 [  2  17  79   2   1   0  33   1  32]
 [  9   3   9 465  12   0  17   1  92]
 [ 62   8   5  16 309  21  11   3  10]
 [  7   2   0   0  10 199   0   0   0]
 [  5  15  36  21   0   0 169  12  28]
 [  3  39   3   0   0   2  24 461  10]
 [ 43  40  81 112   7   0  65   0 281]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.516758241758
[[ 60   7   2   6  37  46  10   1   5]
 [ 31 131  47   1  10  19  29   5  27]
 [  0   0   0   0   0   1   0   0   2]
 [ 46  22  26 557  65   8  34   0 203]
 [ 32   2   0   3 215  16   2   2   2]
 [ 10   4   1   0  17 144   0   0   0]
 [  5  10  24   5   2   0 105   9  22]
 [ 78 127  71   4  19  33  71 472  40]
 [ 66 100 101  43  23  23  99   3 197]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.552747252747
[[ 48   8   1   1  12  11   1   0   5]
 [ 39 183  46   1   9  13  21   5  32]
 [  7  14  60   0   0   2  21   0  19]
 [ 65  39  36 573  87  25  50   0 233]
 [ 66   5   6   8 259  87  11  10   4]
 [ 26   5   1   0  13 136   3   0   1]
 [  6   9  27   7   1   1 130  12  21]
 [ 39  97  22   4   5  14  47 464  24]
 [ 32  43  73  25   2   1  66   1 159]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.439574236403

0.471978021978
[[ 69  54  31  29  28  30  38  20  41]
 [ 59 150  45   3   9  22  34  46  35]
 [ 23  59  72  15   3  13  53   8  41]
 [ 32   7  17 393  36   8  23   0 123]
 [ 40  11   4  28 232  76   4   3  17]
 [ 32  27  10   2  49 120   6   4   3]
 [ 30  28  38  15  12   7 115  20  54]
 [ 10  30   5   1   5   7  25 388   5]
 [ 33  37  50 133  14   7  52   3 179]]

### RandomForestClassifier ###
score.mean():  0.529866898351

0.568956043956
[[ 88  51  30  12  31  37  30   7  41]
 [ 70 211  51   1   5  20  29  31  33]
 [ 15  44  82   7   3   5  43   3  49]
 [ 33   5  14 505  43   4  23   0 125]
 [ 46   6   1  15 260  65   4   4  12]
 [ 22  11   3   0  40 151   4   3   2]
 [ 14  19  47  15   2   1 152   6  45]
 [  8  30   3   0   1   4  19 437   6]
 [ 32  26  41  64   3   3  46   1 185]]

### ExtraTreesClassifier ###
score.mean():  0.54195915735

0.571153846154
[[110  69  32  13  20  43  17   8  35]
 [ 65 206  55   3  10  24  37  37  32]
 [ 21  30  78   4   3   4  35   2  54]
 [ 29   5  17 501  37   5  32   0 129]
 [ 40   2   1  14 263  64   4   2   9]
 [ 18   8   5   0  43 146   4   3   2]
 [ 21  16  42  15   1   0 156   8  44]
 [  3  36   1   0   1   3  21 432   6]
 [ 21  31  41  69  10   1  44   0 187]]

###  BaggingClassifier ###
score.mean():  0.614489644071

0.630769230769
[[127  33   6   1  49  54   4   0   5]
 [ 48 244  48   0   7   3  22  28  30]
 [  5  22  81   0   2   0  38   3  42]
 [ 13   6  13 471  29   0  12   0 115]
 [ 55   5   2  12 273  11   8   2   8]
 [ 26   3   0   0  21 222   0   0   1]
 [  7  20  47  35   2   0 198  23  45]
 [  1  32   2   0   0   0  14 436   8]
 [ 46  38  73 100   5   0  54   0 244]]
######################################################
(5460, 64) (3640, 64)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.561263736264
[[  0 133  82  94 112  97  55  86   5 129]
 [  0  91  16   0   0  27   8   2   1   3]
 [  0  49 214  32   0   5   1  15   7  17]
 [  0   3  11  69   1   2   0  20   0  16]
 [  0  13   2   5 437   5   0  11   0  82]
 [  0  21   2   0   6 244  11   2   0   1]
 [  0  12   5   0   0  11 209   0   0   0]
 [  0   6   8  34  18   0   0 152  13  26]
 [  0   6  51   2   1   1   1  24 458   4]
 [  0  24  29  40  56   4   0  31   0 169]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.643681318681
[[152  49   7   2  47  43   9   2   8]
 [ 55 243  58   2   6   3  24   9  25]
 [  3  14  85   3   2   0  31   1  21]
 [ 13   2   6 455   5   0  15   0  85]
 [ 64   6   3  27 320  29   9   1   9]
 [ 12   5   0   0  11 209   0   0   0]
 [  6   8  34  18   0   0 152  13  26]
 [  6  51   2   1   0   1  24 458   4]
 [ 47  42  81 123   5   0  79   0 269]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.497252747253
[[ 52   4   2   6  37  39   5   0   7]
 [ 32  96  23   0   5   6  23   3  11]
 [  0   0   3   1   0   0   1   0   0]
 [ 52  10  21 547  59  10  29   1 172]
 [ 23   1   0   7 211  25   4   0   0]
 [ 16   7   0   0  22 145   1   2   0]
 [  7   5  19   8   1   0  88   7  20]
 [ 90 167  74   2  26  31  80 466  35]
 [ 86 130 134  60  35  29 112   5 202]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.508241758242
[[ 29   5   2   0   8   4   1   0   3]
 [ 24  99  23   1   3   2  14   2  12]
 [  1   2   7   0   0   0   2   0   2]
 [ 47  11  16 522  39   6  24   0 147]
 [ 67   5   7  19 299 113  11   2   9]
 [ 19  10   1   1  23 126   7   0   4]
 [  4   3  10   8   0   1  69   4   9]
 [100 187  77   2  15  30  99 474  36]
 [ 67  98 133  78   9   3 116   2 225]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.450014386089

0.46043956044
[[ 68  51  22  25  45  35  30  17  29]
 [ 55 155  43   8  12  21  22  49  25]
 [ 36  52  69  23   3   3  49  12  51]
 [ 33   6  22 385  15   4  20   0 104]
 [ 37   9   5  29 232  64   6   3  16]
 [ 30  22   6   9  53 134   8  12  11]
 [ 34  42  46  34   9   5 124  21  61]
 [ 21  42   7   0   5   7  30 364   5]
 [ 44  41  56 118  22  12  54   6 145]]

### RandomForestClassifier ###
score.mean():  0.535193934148

0.565659340659
[[108  65  24  13  40  39  26   9  28]
 [ 69 208  54   3  11  19  33  28  35]
 [ 26  36  89   9   1   4  37   2  48]
 [ 46   4  14 492  30   2  22   0 109]
 [ 26   6   2  21 266  61   3   1   8]
 [ 29  16   5   2  36 150   5   4   5]
 [ 24  19  35  17   4   2 148  11  39]
 [ 10  44   5   0   0   5  24 427   4]
 [ 20  22  48  74   8   3  45   2 171]]

### ExtraTreesClassifier ###
score.mean():  0.537370585647

0.579395604396
[[102  56  20  17  37  33  26   8  31]
 [ 70 235  62   6  17  15  34  24  25]
 [ 22  25  98   4   0   6  42   3  45]
 [ 34   6  11 485  31   2  15   0 106]
 [ 33   6   2  16 259  64   4   0  14]
 [ 33  12   8   2  40 159   5   1   2]
 [ 19  15  28  22   2   1 155   8  40]
 [ 13  45   3   0   1   3  24 439   7]
 [ 32  20  44  79   9   2  38   1 177]]

###  BaggingClassifier ###
score.mean():  0.623106234617

0.628571428571
[[131  31   4   0  55  33   2   1   2]
 [ 70 244  51   0  13   3  27  18  23]
 [  5  22  82   2   7   0  32   0  25]
 [ 18   7   9 466  28   0  11   0 106]
 [ 49   3   1  17 270  20   4   1   4]
 [ 31   9   0   0  17 229   0   0   1]
 [  9  18  50  39   0   0 188  29  39]
 [  2  42   1   1   0   0  14 435   4]
 [ 43  44  78 106   6   0  65   0 243]]
######################################################
(5460, 64) (3640, 64)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.556043956044
[[  0 114  87 118 129 103  59  78   5 120]
 [  0  94   8   0   0  20  11   2   0   2]
 [  0  50 204  38   2   4   0  18  10  29]
 [  0   5   8  61   1   1   0  14   0  16]
 [  0   6   2  10 434   8   0   8   0  91]
 [  0  25   1   0   6 247   9   0   2   5]
 [  0  18   0   0   0  14 213   0   0   0]
 [  0   8  13  38  21   0   0 143  13  35]
 [  0   3  45   2   0   0   1  28 437   4]
 [  0  15  24  39  39   1   0  30   0 191]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.638186813187
[[161  38  12   3  38  49  12   2   9]
 [ 57 227  70   2   8   4  26  13  38]
 [  7  11  81   3   2   0  27   0  19]
 [  6   2  13 455   8   0  11   0  93]
 [ 45   9   2  22 323  26   5   3  11]
 [ 18   0   0   0  14 213   0   0   0]
 [  8  13  38  21   0   0 143  13  35]
 [  3  45   2   0   0   1  28 436   4]
 [ 33  47  88 126   5   0  69   0 284]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.502472527473
[[ 54   7   6   4  38  51  10   3   5]
 [ 36 107  37   1  13  14  16   5  29]
 [  0   1   9   0   0   1   1   0   3]
 [ 41  18  29 543  58   8  33   0 192]
 [ 23   2   0   6 222  20   0   2   5]
 [ 17   1   1   0  25 148   0   0   0]
 [  7   6  22  10   2   0  96   9  19]
 [ 86 159  85   3  18  31  79 446  36]
 [ 74  91 117  65  22  20  86   2 204]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.548901098901
[[ 37   7   5   1   9   5   4   0   1]
 [ 45 148  43   1   9   7  20   4  33]
 [  5   6  50   1   0   0  13   0  18]
 [ 66  29  43 561  74  12  51   0 222]
 [ 47   6   2  13 274  55   7   9   9]
 [ 38  15  14   1  27 200   5   1   3]
 [  8   8  32  12   0   0 118   6  20]
 [ 53 128  39   0   5  13  50 447  24]
 [ 39  45  78  42   0   1  53   0 163]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.451490467733

0.462912087912
[[ 61  49  34  28  37  40  30  22  30]
 [ 55 157  60   7  12  30  34  47  29]
 [ 27  48  78  17   2   6  46   4  51]
 [ 26   8  18 392  28   1  23   1 129]
 [ 35   9   7  38 228  53   5   3  21]
 [ 40  23   6  11  72 146   6   9   8]
 [ 31  32  45  29   7   5 112  18  67]
 [ 16  44   5   1   0   3  26 360   7]
 [ 47  22  53 109  12   9  39   3 151]]

### RandomForestClassifier ###
score.mean():  0.547649323382

0.556318681319
[[ 88  48  26  20  39  31  32  16  31]
 [ 81 210  66   3  10  28  38  29  41]
 [ 19  31  96   9   4   1  25   0  49]
 [ 34   4  16 488  29   1  22   0 124]
 [ 35   2   2  22 263  67   2   1  10]
 [ 30  14   4   2  46 155   4   5   5]
 [ 15  28  44  20   2   3 130  10  41]
 [  9  37   4   0   1   4  21 406   3]
 [ 27  18  48  68   4   3  47   0 189]]

### ExtraTreesClassifier ###
score.mean():  0.543065117743

0.569505494505
[[ 91  33  33  18  34  26  22   9  29]
 [ 77 236  62   7  12  31  37  30  40]
 [ 26  25  98   5   4   4  32   1  45]
 [ 29   2  19 492  27   4  18   0 133]
 [ 37   3   4  19 267  60   3   2  13]
 [ 35  14   2   1  42 160   3   4   0]
 [ 19  23  35  23   4   1 136   7  48]
 [  8  34   3   0   2   2  17 414   6]
 [ 16  22  50  67   6   5  53   0 179]]

###  BaggingClassifier ###
score.mean():  0.622924195956

0.626098901099
[[146  26   6   0  46  37   4   0   3]
 [ 61 234  66   2  13   3  26  26  33]
 [  7  24  74   2   7   0  26   1  20]
 [ 12   6  14 467  21   0   8   0 119]
 [ 36   2   1  13 276  15   4   3  11]
 [ 36   2   0   0  29 238   0   0   0]
 [ 13  25  57  46   0   0 181  24  53]
 [  0  34   2   0   0   0  15 413   4]
 [ 27  39  86 102   6   0  57   0 250]]
######################################################
(5460, 64) (3640, 64)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.55989010989
[[  0 140  72 107 100  96  64  93   5 133]
 [  0  66  14   0   0  26   8   1   0   1]
 [  0  42 214  36   2   4   0  10  12  22]
 [  0   3  10  68   0   2   0  22   0  14]
 [  0   5   1   8 469   8   0   8   0  99]
 [  0  31   4   0   4 258   6   4   0   1]
 [  0  10   2   0   0  12 194   0   0   0]
 [  0   7  12  24  20   0   0 143   8  27]
 [  0   4  50   4   1   1   2  28 438   8]
 [  0  19  31  38  41   1   0  34   0 188]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.642032967033
[[130  37   8   4  44  45   9   1   5]
 [ 53 244  60   5   7   6  17  13  32]
 [  4  11  85   3   2   0  43   1  19]
 [  5   1   9 482   8   0  18   0 106]
 [ 66   6   2  13 331  27  13   2   6]
 [ 10   2   0   0  12 194   0   0   0]
 [  7  12  24  20   0   0 143   8  27]
 [  4  50   4   1   1   2  28 438   8]
 [ 48  47  93 109   3   0  72   0 290]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.504120879121
[[ 40   6   3   2  28  49  10   1   2]
 [ 36 117  36   2   9   9  25   4  20]
 [  0   0   1   0   0   0   0   0   0]
 [ 38  19  25 559  70   5  37   0 196]
 [ 33   1   0   6 218  11   5   0   1]
 [ 17   8   1   0  31 139   1   0   0]
 [  7   9  18   8   1   0  93   6  19]
 [ 80 151  81   3  25  39  80 450  37]
 [ 76  99 120  57  26  22  92   2 218]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.533241758242
[[ 33   3   1   0  10  11   4   1   0]
 [ 45 165  43   2  10   7  20   4  25]
 [  5  10  48   0   1   0  20   0  16]
 [ 60  32  35 580  94  16  44   0 226]
 [ 57   6   2   7 262  78  16   1   3]
 [ 13   2   3   0  13 114   1   0   1]
 [  8  12  16  12   0   1 113   8  22]
 [ 65 135  48   2  15  46  59 449  23]
 [ 41  45  89  34   3   1  66   0 177]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.451677981832

0.456043956044
[[ 61  70  33  23  37  37  35  11  37]
 [ 44 125  56   6  10  25  42  41  35]
 [ 35  50  65  14   7   5  39   6  52]
 [ 23   9  18 415  30   4  24   1 129]
 [ 39  11   2  17 242  58   7   1  20]
 [ 41  23  12   3  58 125   8   9   4]
 [ 23  39  41  32   6   4  93  15  50]
 [ 15  50   7   2   2  11  35 374   6]
 [ 46  33  51 125  16   5  60   5 160]]

### RandomForestClassifier ###
score.mean():  0.537564568917

0.567857142857
[[ 78  49  32  12  28  22  26  10  33]
 [ 74 214  72   4  10  20  24  22  37]
 [ 27  24  87   4   3   8  37   2  54]
 [ 26   5  18 514  34   3  25   0 144]
 [ 41   8   0  11 272  60   4   0   3]
 [ 28  15   5   0  52 156   5   3   1]
 [ 18  18  33  17   1   2 149  11  34]
 [  7  47   4   1   1   3  15 415   5]
 [ 28  30  34  74   7   0  58   0 182]]

### ExtraTreesClassifier ###
score.mean():  0.539423384698

0.570604395604
[[ 93  62  32  14  34  27  26  10  22]
 [ 73 205  68   2  15  28  28  22  34]
 [ 19  25  84   4   5   2  44   0  57]
 [ 30   4  15 511  31   4  22   0 124]
 [ 46   3   4  12 266  52   8   0   9]
 [ 24  13   5   0  44 156   3   1   3]
 [ 14  26  31  20   0   1 141   9  39]
 [  3  46   3   2   3   4  22 420   4]
 [ 25  26  43  72  10   0  49   1 201]]

###  BaggingClassifier ###
score.mean():  0.612303037273

0.630769230769
[[122  32   3   0  47  33   6   0   2]
 [ 54 242  61   1  12   4  16  24  27]
 [  5  14  75   2   6   0  37   0  32]
 [ 10   3  12 496  27   0   9   0 124]
 [ 47   3   2  10 287  13  11   2   4]
 [ 31   5   0   0  24 224   0   0   0]
 [ 11  24  45  39   0   0 191  25  50]
 [  0  38   4   1   1   0  13 412   7]
 [ 47  49  83  88   4   0  60   0 247]]
######################################################
(5460, 64) (3640, 64)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.576373626374
[[  0 127  73 114 112  99  52  75   6 129]
 [  0  91   8   0   0  26   9   7   1   3]
 [  0  32 219  47   0   4   1  20   4  20]
 [  0   2  12  70   0   0   0  11   0  11]
 [  0   4   1  11 478  12   0   4   0  77]
 [  0  38   2   0   4 253  11   1   2   1]
 [  0  10   2   0   0  10 173   0   0   0]
 [  0   2  13  31  16   0   0 155  16  31]
 [  0   6  50   5   0   5   4  15 467   3]
 [  0  10  21  37  44   1   0  37   0 192]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.655769230769
[[159  37  11   4  49  44  16   3  10]
 [ 39 240  72   3   5   5  25   7  29]
 [  2  12  88   1   1   0  27   1  19]
 [  4   1  11 492  12   0   7   0  81]
 [ 64   4   1  17 325  24  10   2   6]
 [ 10   2   0   0  10 173   0   0   0]
 [  2  13  31  16   0   0 155  16  31]
 [  6  50   5   0   3   4  15 467   3]
 [ 36  42  96 121   5   0  70   0 288]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.503846153846
[[ 46   1   3   5  36  45  15   3   5]
 [ 29 115  55   2   8   9  22   5  24]
 [  0   0   1   0   0   0   1   0   0]
 [ 42  18  33 576  69  11  18   0 184]
 [ 34   1   0   3 213  13   2   2   1]
 [ 20   5   0   0  26 121   1   2   0]
 [  2   8  17   7   0   0  92  12  21]
 [ 74 150  83   0  20  30  60 469  31]
 [ 75 103 123  61  38  21 114   3 201]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.54478021978
[[ 27   3   2   0  11   6   2   0   2]
 [ 32 132  42   0   6   8  24   2  16]
 [  0   7  29   0   0   0   6   0   4]
 [ 37  12  28 559  42   5  13   0 147]
 [ 85  11   9  15 325 114  21  12  10]
 [ 13   2   0   0   4  84   1   0   0]
 [  5  13  38   7   0   1 130  23  36]
 [ 64 127  43   0  11  26  26 459  14]
 [ 59  94 124  73  11   6 102   0 238]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.443237556388

0.475274725275
[[ 64  53  33  31  48  26  33  13  41]
 [ 48 133  63   6  10  23  38  37  33]
 [ 25  54  75  13   2   5  51   6  56]
 [ 20   8  20 445  28   1  14   0  97]
 [ 55  12   9  23 238  60   2   1  13]
 [ 33  21   6   9  54 110   6  10   3]
 [ 29  34  45  26   3  10 113  36  54]
 [ 14  55   7   2   4  10  18 386   4]
 [ 34  31  57  99  23   5  50   7 166]]

### RandomForestClassifier ###
score.mean():  0.539388421437

0.566483516484
[[ 64  45  32  20  39  34  28  13  30]
 [ 76 203  85   5   6  13  34  21  26]
 [ 11  27  88   6   5   1  25   2  42]
 [ 32   5  22 529  39   2  18   0 127]
 [ 57   3   1  11 268  39   5   2   7]
 [ 34  17   7   2  45 149   4   2   4]
 [ 16  23  36  12   1   3 150  17  55]
 [ 10  53   5   0   2   5  13 438   3]
 [ 22  25  39  69   5   4  48   1 173]]

### ExtraTreesClassifier ###
score.mean():  0.531326580091

0.563186813187
[[ 91  48  32  22  30  28  29   9  29]
 [ 55 200  85   4  19  19  32  28  37]
 [ 18  21  86   7   2   3  26   2  41]
 [ 24   6  20 517  35   3  26   0 113]
 [ 46   5   2  13 266  45   5   2   8]
 [ 28  24   4   0  48 143   4   2   1]
 [ 20  16  33  11   0   3 137  24  51]
 [ 12  59   5   0   3   5   9 429   6]
 [ 28  22  48  80   7   1  57   0 181]]

###  BaggingClassifier ###
score.mean():  0.611743317863

0.635989010989
[[136  25   7   1  57  27   8   1   5]
 [ 46 244  77   1  16   5  26  24  25]
 [  6  17  88   1   4   0  29   4  24]
 [  6   7  16 500  30   0   7   0 104]
 [ 56   2   0  15 275  17   6   2   3]
 [ 29   3   0   0  21 201   0   0   0]
 [  8  25  49  40   1   0 181  32  46]
 [  2  41   3   0   1   0   5 433   3]
 [ 33  37  75  96   5   0  63   0 257]]
######################################################
(5460, 64) (3640, 64)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.572802197802
[[  0 128  82  92 101  91  63  97   4 115]
 [  0  89   8   0   0  24   9   2   0   4]
 [  0  40 216  27   0   5   1  15  16  27]
 [  0   2   9  72   2   2   0  16   0  11]
 [  0   6   0   8 461   8   0   8   0  78]
 [  0  41   1   0   6 269   9   2   0   6]
 [  0  13   1   0   0  10 196   0   0   0]
 [  0   7  12  32  11   0   0 153  13  27]
 [  0   8  58   4   0   3   2  16 448   6]
 [  0  21  29  33  53   3   0  27   0 181]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.653571428571
[[165  32  10   1  46  49  12   1   9]
 [ 48 246  40   1   8   6  23  17  38]
 [  2  12  97   3   3   0  31   1  15]
 [  6   0   8 476   8   0  13   0  79]
 [ 69   6   1  17 330  27  12   3  11]
 [ 13   1   0   0  10 196   0   0   0]
 [  7  12  32  11   0   0 153  13  27]
 [  8  58   4   0   2   2  16 446   6]
 [ 37  49  76 125   8   0  76   0 270]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.504945054945
[[ 45   2   1   2  29  35   9   1   5]
 [ 36 108  25   1   6   9  16   5  17]
 [  0   1   8   0   0   1   4   0   1]
 [ 40  16  26 561  63  10  28   0 178]
 [ 41   3   0   6 224  19   4   1   6]
 [ 19   3   1   0  29 148   2   1   0]
 [  6  10  17   7   0   0  87  11  17]
 [ 88 137  83   1  33  29  72 460  34]
 [ 80 136 107  56  31  29 114   2 197]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.521703296703
[[ 33   4   0   1  11   8   2   0   3]
 [ 32 132  14   1   3   5  14   0  17]
 [  1   7  29   1   0   0   8   0   5]
 [ 46  17  28 565  42   8  27   0 191]
 [ 88   9   3  14 320 114  22   5  11]
 [  5   1   1   0   9  98   2   1   0]
 [  3  13  17   8   0   1  86   6  19]
 [107 174  95   1  25  44 107 469  42]
 [ 40  59  81  43   5   2  68   0 167]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.459905734373

0.45467032967
[[ 62  42  26  39  39  40  29  18  48]
 [ 69 160  45  13  16  21  45  38  43]
 [ 16  51  71  19   5   6  43   4  52]
 [ 38   8  13 411  26   5  37   1 114]
 [ 52  10   6  28 231  53  13   1  14]
 [ 38  20  11   2  74 124   6   9   2]
 [ 22  35  45  18   7  12  99  33  52]
 [ 20  47   5   0   2   8  26 371   4]
 [ 38  43  46 104  15  11  38   6 126]]

### RandomForestClassifier ###
score.mean():  0.543800451968

0.564285714286
[[ 79  52  32  16  27  38  26   7  42]
 [ 83 228  61   3  21  19  39  23  34]
 [ 17  33  68   8   0   1  35   4  41]
 [ 26   5  11 485  28   6  19   0  95]
 [ 56   3   3  18 273  53   4   1   8]
 [ 29   9   5   0  55 153   7   5   0]
 [ 23  16  36  13   2   1 147  15  33]
 [ 16  40   4   0   0   3  15 425   6]
 [ 26  30  48  91   9   6  44   1 196]]

### ExtraTreesClassifier ###
score.mean():  0.535003805054

0.559065934066
[[ 88  51  33  18  35  31  21  11  25]
 [ 79 228  55   8  18  25  37  25  35]
 [ 21  40  83   6   4   7  44   4  50]
 [ 30   3  15 489  32   2  27   0 105]
 [ 58   1   0  22 262  50   7   1   8]
 [ 26  11   6   0  49 158   5   4   5]
 [ 23  19  34  13   0   1 137  20  49]
 [ 12  39   2   0   2   4  11 415   3]
 [ 18  24  40  78  13   2  47   1 175]]

###  BaggingClassifier ###
score.mean():  0.615595163691

0.630494505495
[[137  24   7   0  49  39   4   0   6]
 [ 58 247  46   1  13   4  25  24  37]
 [  3  26  80   4   5   0  33   1  20]
 [ 13   4  15 482  30   0  11   0 106]
 [ 56   2   0  14 286  15   8   2   9]
 [ 38   4   0   0  23 222   0   0   0]
 [ 12  25  53  29   1   0 184  35  33]
 [  1  42   1   0   0   0  11 419   6]
 [ 37  42  66 104   8   0  60   0 238]]
######################################################
(5460, 64) (3640, 64)

******************************************************
Combinacoes:
### lda + svm ### 

----------------
LDA:

----------------
SVM:
combe: 

0.568956043956
[[  0 148  84 102 109  73  73  86   3 129]
 [  0  77   3   0   1  22   7   2   0   2]
 [  0  43 210  51   0   2   2  22  15  24]
 [  0   2  10  74   1   2   0  18   0   9]
 [  0   6   2   6 450   7   0   8   0  71]
 [  0  27   1   0   2 285   6   1   2   6]
 [  0  12   2   0   0  13 198   0   0   0]
 [  0   6  10  28  23   0   0 139  14  19]
 [  0   7  46   3   0   1   1  22 456   4]
 [  0  20  21  43  40   2   0  42   0 182]]
### knn + lda + svm ### 

----------------
KNN:

----------------
LDA:

----------------
SVM:
combe: 

0.645054945055
[[145  33   7   4  39  57   6   1   5]
 [ 52 233  71   2   4   5  30  15  26]
 [  3  11  94   1   2   0  25   0  16]
 [  6   4   9 457   7   0  12   0  74]
 [ 68   7   1  12 339  26   8   5  14]
 [ 12   2   0   0  13 198   0   0   0]
 [  6  10  28  23   0   0 139  14  19]
 [  7  46   3   0   0   1  22 455   4]
 [ 49  43  94 127   3   0  98   0 288]]
------------------------------
### log_mul + svm + bayes ### 

----------------
Logistic Regression - mul:

----------------
SVM:

----------------
Gaussian Naive Bayes:
combe: 

0.50467032967
[[ 46   2   4   7  31  47   6   0   6]
 [ 34 118  42   1  11  19  27   7  18]
 [  0   0   2   0   0   0   0   0   0]
 [ 41  18  33 549  56   7  37   0 169]
 [ 29   2   0   3 237  13   1   4   5]
 [ 18   4   0   0  26 133   0   1   0]
 [  5   5  19   7   1   0  78  11  11]
 [ 84 131  77   2  12  30  66 464  27]
 [ 91 109 130  57  33  38 125   3 210]]
------------------------------
### all ### 

----------------
Decision Tree:

----------------
Gaussian Naive Bayes:

----------------
KNN:

----------------
SVM:

----------------
Perceptron:

----------------
LDA:

----------------
Logistic Regression - ovr:

----------------
Logistic Regression - mul:
combe: 

0.554120879121
[[ 36   3   2   1  13   9   1   0   2]
 [ 48 171  47   1   8  12  24   6  25]
 [  1  10  57   0   3   1   9   0   8]
 [ 60  31  41 567  73  21  46   0 187]
 [ 68   5   6   9 289  80   9   8   8]
 [ 27   8   3   0  15 143   1   1   0]
 [  7   5  23   9   0   1  97  10  11]
 [ 53 105  33   1   5  14  51 462  10]
 [ 48  51  95  38   1   6 102   3 195]]

******************************************************
Ensembles:

### DecisionTreeClassifier ###
score.mean():  0.442154044552

0.469505494505
[[ 77  40  38  17  43  29  30  19  36]
 [ 54 166  52   5   9  27  43  54  25]
 [ 16  43  70  17   4   9  43   7  59]
 [ 40   9  14 418  23   3  29   0 106]
 [ 39   7   6  27 241  64   4   1  15]
 [ 38  22   5   5  67 126   5   7   7]
 [ 27  23  41  23   9   9 105  23  53]
 [ 22  41   9   0   1   9  19 365   4]
 [ 35  38  72 114  10  11  62  14 141]]

### RandomForestClassifier ###
score.mean():  0.544711678076

0.562637362637
[[ 81  38  40   9  33  45  27   7  34]
 [ 71 221  71   3   9  30  42  25  40]
 [ 11  19  85   3   3   1  36   0  39]
 [ 40   7  15 495  28   3  18   0 124]
 [ 41   5   1  15 285  59   4   2   7]
 [ 31   9   2   1  40 140   0   1   4]
 [ 18  18  37  16   2   2 136  19  23]
 [ 17  49   5   0   0   5  19 433   3]
 [ 38  23  51  84   7   2  58   3 172]]

### ExtraTreesClassifier ###
score.mean():  0.53080199185

0.571153846154
[[104  42  28  14  28  33  20   8  30]
 [ 73 213  71   1  12  27  32  31  33]
 [ 10  22  96   7   3   2  45   1  38]
 [ 29   5  19 489  32   4  23   0 112]
 [ 37   2   3  18 276  52   4   1  13]
 [ 28  14   6   0  47 163   4   1   2]
 [ 22  13  36  20   3   1 125  15  32]
 [ 16  51   3   0   1   2  21 432   5]
 [ 29  27  45  77   5   3  66   1 181]]

###  BaggingClassifier ###
score.mean():  0.616139862094

0.626648351648
[[131  24   3   1  52  48   2   0   3]
 [ 61 236  64   1   7   4  31  29  28]
 [  6  16  85   2   4   0  32   0  22]
 [ 13   6  13 466  26   0   9   0 101]
 [ 56   3   1   9 298  19   5   4   8]
 [ 26   1   0   0  15 216   0   0   0]
 [ 12  24  51  33   2   0 169  28  30]
 [  2  37   3   0   0   0  12 429   3]
 [ 41  42  87 114   3   0  80   0 251]]
######################################################
######################################################
comb 0 :
[ 0.55741758  0.55989011  0.55631868  0.56456044  0.56126374  0.55604396
  0.55989011  0.57637363  0.5728022   0.56895604]
0.563351648352
comb 1 :
[ 0.63489011  0.64532967  0.63983516  0.64752747  0.64368132  0.63818681
  0.64203297  0.65576923  0.65357143  0.64505495]
0.644587912088
comb 2 :
[ 0.49642857  0.49120879  0.48846154  0.51675824  0.49725275  0.50247253
  0.50412088  0.50384615  0.50494505  0.50467033]
0.501016483516
comb 3 :
[ 0.53516484  0.50027473  0.53049451  0.55274725  0.50824176  0.5489011
  0.53324176  0.54478022  0.5217033   0.55412088]
0.532967032967
comb 4 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 5 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 6 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 7 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 8 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
comb 9 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 0 :
[ 0.45961538  0.46923077  0.4717033   0.47197802  0.46043956  0.46291209
  0.45604396  0.47527473  0.45467033  0.46950549]
0.465137362637
ens 1 :
[ 0.57142857  0.55906593  0.55027473  0.56895604  0.56565934  0.55631868
  0.56785714  0.56648352  0.56428571  0.56263736]
0.563296703297
ens 2 :
[ 0.56923077  0.55576923  0.56016484  0.57115385  0.5793956   0.56950549
  0.5706044   0.56318681  0.55906593  0.57115385]
0.566923076923
ens 3 :
[ 0.62472527  0.6271978   0.6260989   0.63076923  0.62857143  0.6260989
  0.63076923  0.63598901  0.63049451  0.62664835]
0.628736263736
ens 4 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 5 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 6 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 7 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 8 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
ens 9 :
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
0.0
